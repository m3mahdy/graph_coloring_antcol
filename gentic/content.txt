
❑ Common Concepts for Population-Based Metaheuristics
 Generation
 Selection
 Initial Population
 Stopping Criteria
❑ Evolutionary Algorithms
 Genetic Algorithms
 Evolution Strategies
 Evolutionary Programming
 Genetic Programming
Population Based metaheuristics
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
3
❑ Population based metaheuristics (P-metaheuristics) can be 
viewed as an iterative improvement in a population of 
solutions
❑ First the population is initialized. Then, a new population of 
solutions is generated
❑ Finally, this new population is integrated into the current one 
using some selection procedure
❑ The search process stops when a given condition is satisfied 
(stopping criterion)
❑ Examples of P-metaheuristics are: Evolutionary Algorithms 
(EA), Scatter Search (SS), Particle Swarm Optimization (PSO), 
Ant Colony Optimization (ACO), Bee Colony (BC), and Artifical
Immune Systems (AIS)
Common Concepts for P-metaheuristics
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
4
❑ P-metaheuristics start from an initial population of solutions that 
may be complete, partial, or empty solutions
❑ Then they iteratively apply the generation of a new population and 
the replacement of the current population
 Generation Phase: a new population is created
 Replacement Phase: selection is carried out from the current and new 
populations
❑ The process is repeated until some stopping criterion
❑ The generation and replacement phases may be memoryless→
based only on the current population
❑ Otherwise, some search history may be used in the generation and 
replacement phases
❑ Most of the P-metaheuristics are nature inspired
❑ They differ in the way they perform the generation and selection 
and the search memory they are using during the search
Common Concepts for P-metaheuristics
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
5
Common Concepts for P-metaheuristics
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
6
❑ Search Memory: 
 Represents the set of information extracted and memorized 
during the search
 In some cases (e.g. EA) the search memory is limited to the 
population of solutions
 In ACO, the pheromone matrix is the main concept of the 
search memory
Common Concepts for P-metaheuristics
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
7
❑ Generation: P-metaheuristics may be classified into two 
main categories:
1. Evolution based: solutions are selected and reproduced using 
variation operators (e.g., mutation and recombination) acting 
directly on their representations. The recombination operator may 
involve two or more solutions
2. Blackboard based: solution of the population participate in the 
construction of a shared memory, which will be used as the main 
input for generating the new population.
➢ Recombination is indirect through the shared memory. 
➢ ACO belongs to this class, where solutions generated by past ants affect 
solutions generated by future ants via the pheromone
Common Concepts for P-metaheuristics
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
8
Common Concepts for P-metaheuristics
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
9
❑ Replacement: The last step in P-metaheuristics is 
replacement, which means selecting the new population 
from the union of the old population and the generated 
population
 In the traditional strategy the newly generated population 
replaces the old one
 Other strategies use elitism where the best solutions from 
both sets are selected
 In the blackboard based P-metaheuristics there is no explicit 
selection. The old population will update the shared search 
memory, which will affect the generation of the new 
population
Common Concepts for P-metaheuristics
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
10
❑ Initial Population:
❑ P-metaheuristics are naturally more exploration search 
algorithms whereas S-metaheuristics are more 
exploitation search algorithms
❑ The determination of the initial solutions plays a crucial 
role in the effectiveness and efficiency of the algorithm
❑ In the generation of the initial population, the main issue 
is diversification→ if the initial population is not well 
diversified, premature convergence may happen. For 
example, this may happen when a greedy heuristic is 
used to generate the initial population
Common Concepts for P-metaheuristics
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
11
❑ Strategies for generating the new population may be classified 
into four categories:
1. Random generation: usually the initial population may be 
generated randomly. For example, in continuous 
optimization, the initial value of each variable may be 
generated randomly within a selected range
2. Sequential Diversification: solutions are generated in 
sequence such that diversity is optimized. 
 Example: given Q the current subpopulation which is initially composed of 
only one randomly picked solution. Any new selected solution must be at a 
minimum distance Δ to all other solutions of Q. Hence, a random solution 
is repeatedly generated until this condition is satisfied
 The drawback of this strategy is the high computation cost
Common Concepts for P-metaheuristics
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
12
3. Parallel Diversification: The solutions of a population 
are generated in parallel
 Example: Diversified initial populations of permutations:
➢ For each object i and for each location j, there is a solution of the initial 
population in which the object i is mapped to the location j
X1: 5 3 2 1 6 4
X2: 6 2 3 5 4 1
X3: 4 5 6 2 1 3
X4: 3 1 4 6 5 2
X5: 2 6 1 4 3 5
X6: 1 4 5 3 2 6
Common Concepts for P-metaheuristics
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
13
4. Heuristic Initialization:
 Any heuristic can be used to initialize the population. 
For example, a greedy heuristic can be used
 If this strategy is used in the P-metaheuristic, it is 
obvious to randomize the greedy procedure to obtain 
different solutions ( a population)
 The main drawback of this strategy is that the initial 
population may lose its diversity, which will generate 
a premature convergence and the stagnation of the 
population
Common Concepts for P-metaheuristics
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
14
❑ Stopping Criteria: can be classified into two categories:
 Static Procedure: the end of the search is known a priori. For 
example, a fixed number of iterations (generations), a limit on CPU 
resources, or a maximum number of objective function evaluations
 Adaptive Procedure: The end of the search is not known a priori. For 
example, a fixed number of generations without improvement, 
when an optimum or satisfactory solution is reached, or a solution 
with a certain distance to the optimum is reached
➢ Some stopping criteria may be related to the diversity of the 
population, i.e., stopping the algorithm when the diversity 
measure falls below a given threshold→ stagnation of the 
population
Evolutionary Algorithms (EA)
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
15
❑ EAs are stochastic P-metaheuristics that have been 
applied to many real and complex problems
❑ They are the most studied population-based 
metaheuristics
❑ Their success in solving difficult optimization problems in 
various domains (continuous or combinatorial 
optimization, planning and control, engineering design, 
data mining and machine learning, etc.) has promoted 
the field known as evolutionary computation
❑ EAs are based on the notion of competition and 
evolution of species
Evolutionary Algorithms (EA)
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
16
❑ They are based on the evolution of a population. 
Initially this population is usually generated at 
random
❑ Every individual in the population is the encoded 
version of a tentative solution
❑ An objective function associates a fitness value with 
each solution, indicating its suitability to the problem
❑ At each step, individuals are selected to form the 
parents, such that individuals with higher fitness have 
more probability of being selected
❑ Then the selected individuals are reproduced using 
variation operators (e.g. crossover, mutation) to 
generate new offspring 
❑ Finally, a replacement scheme is applied to 
determine which individuals will survive from the 
offspring and the parents
❑ This process is repeated until a stopping criteria hold
Evolutionary Algorithms (EA)
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
17
1 0 1 1
0 0 0 1
18
Evolutionary Algorithms (EA)
0 0 1 1
0 0 0 1
0 1 1 0
1 0 0 1
1 0 0 0
selection
0 1 0 1
0 0 1 1
1 0 0 1
crossover
parents
children
ith population
(i + 1)th population 0 0 1 1
1 1 0 1
0 0 0 0
1 0 0 1
1 0 1 1
0 1 0 1
ith generation
0 0 0 1
Evolutionary Algorithms (EA)
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
19
❑ In EAs the genotype represents 
the encoding, while the 
phenotype represents the 
solution
❑ The variation operators act on the 
genotype level, while the fitness 
function will use the phenotype 
of the associated individual
❑ The fitness of an individual 
measures its ability to survive in 
its environment
❑ A decoding function is used to 
transform the genotype into a 
phenotype
Evolutionary Algorithms (EA)
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
20
❑ Different main schools of EA has evolved independently over 
the last few decades
❑ Genetic Algorithms (GA) was developed in Michigan, USA by J. 
Holland (1970s)
❑ Evolution Strategies (ES) developed in Germany by I. 
Rechenberg and H-P. Schwefel (1960s)
❑ Evolutionary Programming by L. Fogel in San Diego, USA 
(1960s)
❑ Genetic Programming has been proposed by J. Kosa (1990s)
❑ All these approaches are inspired by the principles of natural 
evolution
Evolutionary Algorithms (EA)
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
21
Algorithm Origin Representation Main Operator Focus
GA J. Holland (USA) 
(1970s)
Binary strings 
(later real-coded)
Crossover + 
mutation
General 
optimization
ES
Rechenberg & 
Schwefel (Germany)
(1960s)
Real-valued 
vectors
Mutation + self-adaptation
Engineering, 
continuous 
optimization
EP L. Fogel (USA)
(1960s)
Finite State 
machines Mutation only
Behavioral 
modeling, 
prediction
GP J. Koza (USA) 
(1990s)
Tree-structured 
programs
Crossover + 
mutation
Program 
evolution, 
symbolic 
regression
Genetic Algorithms (GA)
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
22
❑ GAs are a very popular class of EAs. They were traditionally 
associated with binary representation but nowadays GAs use 
any other type of representation
❑ A GA usually applies a crossover operator to two solutions 
that plays a major role, plus a mutation operator that 
randomly modifies the individual contents to promote 
diversity
❑ The selection is usually proportional selection and the 
replacement is generational (parents are replaced by 
offspring)
❑ Crossover is based on n-point or uniform crossover, while 
mutation is bit flipping
❑ A fixed probability is associated with crossover and mutation
23
Genetic Algorithms (GA)
Original simple GA developed by Holland
24
Evolution Strategy (ES)
Original simple GA developed by Holland
❑ ES are mostly applied to continuous optimization problems, where 
representations are based on real-valued vectors
❑ Crossover is rarely used
❑ The offspring may compete with the parent (best one is kept), or it may 
replace the parent (parent always discarded)
❑ An individual is composed of the float decision variables plus some other 
parameters guiding the search→ ES facilitate self-adaptation by evolving 
the solution as well as strategy parameters
25
Evolutionary Programming (EP)
Original simple GA developed by Holland
❑ EP emphasizes on mutation and does not use 
recombination (crossover)
❑ Traditionally it was developed to evolve finite state 
machines
FSM parsing word nice
Genetic Programming (GP)
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
26
❑ GP is a major variation compared to 
the classical GA
❑ The evolving individuals are 
themselves programs (nonlinear 
representation based on trees)
❑ Parent selection is fitness 
proportional, and the survivor 
selection is a generational 
replacement
❑ The crossover operator is based on 
sub-tree exchange and the mutation 
is based on random change in the 
tree
❑ GPs are widely used in machine 
learning and data mining tasks such 
as prediction and classification




❑ Common Concepts of EAs
 Selection
 Reproduction
 Replacement
 Parameters of Eas
❑ Scatter Search
Common Concepts of EAs
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
3
1. Representation: the encoded solution is referred to as 
chromosome while the decision variables within the 
solution (chromosome) are genes. The possible values 
of the variables (genes) are the alleles and the position 
of an element (gene) within a chromosome is named 
locus
Chromosome 
Gene
allele
Locus
1 2 3 4
x1 x2 x3 x4
Common Concepts of EAs
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
4
2. Population Initialization: A common search component as 
previously discussed
3. Objective function: In the EA community, the term fitness 
refers to the objective function
4. Selection Strategy: “Which parents are chosen for 
reproduction, with a bias toward better fitness?”
5. Reproduction Strategy: Designing suitable mutation and 
crossover operators to generate new individuals (offspring)
6. Replacement Strategy: The new offspring compete with old 
individuals for their place in the next generation (survival of 
the fittest)
7. Stopping Criteria: Common search component for all Pmetaheuristics, as previously discussed
Selection Methods
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
5
❑ The main principle of selection methods is “the better is an 
individual, the higher is its chance of being parent”
❑ Such selection pressure will drive the population to better solutions
❑ However, bad individuals should not be discarded and they have 
some chance of being selected
❑ The selection strategy determines which individuals are chosen for 
mating (reproduction) and how many offspring each selected 
individual produces
❑ In EAs, fitness assignment to individuals may take two different 
ways:
❑ Proportional Fitness Assignment: absolute fitness values are 
associated with individuals
❑ Rank-based Fitness Assignment: relative fitness values are assigned 
to individuals. For example a rank in the population is assigned to 
each individual according to its fitness
Selection Methods
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
6
❑ Parents are selected based on their fitness using one of 
the following strategies:
❑ Roulette Wheel Selection:
 The most common selection strategy
 Assign to each individual a selection probability that is proportional 
to its relative fitness
 pi = f i
/ (∑ f j
)
j=1
n
Selection Methods
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
7
❑ Suppose a pie graph where each individual 
is assigned a space on the graph that is 
proportional to its fitness
❑ An outer roulette wheel is placed around 
the pie
❑ The selection of μ individuals is performed 
by independent μ spins of the roulette 
wheel
❑ Each spin will select a single individual
❑ Better individuals have more space and 
more chance of being selected
❑ However, outstanding individuals may 
introduce a bias in the beginning of the 
search that may cause a premature 
convergence
Selection Methods
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
8
❑ Stochastic Universal Sampling 
(SUS):
❑ To reduce the bias of the roulette 
wheel selection, SUS may be used
❑ An outer roulette wheel is placed 
around the pie with μ equally 
spaced pointers
❑ A single spin of the roulette wheel 
will simultaneously select all the μ
individuals for reproduction
Selection Methods
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
9
❑ Tournament Selection:
❑ Randomly selecting k individuals; the parameter k is called the size 
of the tournament
❑ A tournament is then applied to the k members of the group to 
select the best one
❑ To select μ individuals, the tournament procedure is repeated μ
times
Selection Methods
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
10
❑ Rank- Based Selection:
❑ Instead of using the fitness value of the individual, the rank of 
the individual is used
❑ The function is biased towards individuals with higher rank 
(i.e., good fitness)
❑ The rank may be scaled linearly using the following formula
p(i) = 2-s + 2 . r(i) (s-1)
 μ μ (μ -1)
❑ Where s is the selection pressure (1.0 < s ≤ 2.0), μ is the size 
of the population, and r(i) is the rank associated with 
individual i
❑ If s is large, more importance is given to better individuals
Selection Methods
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
10
0.33 1 0.67 0.33 0.67 0.5
Reproduction
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
12
❑ Once the individuals are selected to form parents, the 
reproduction (variation) phase applies variation operators as 
the mutation (unary operator) and crossover (binary operator)
❑ Mutation:
❑ It is a unary operator acting on a single individual
❑ Represents small changes of the selected individual
❑ The probability pm represents the probability to mutate each 
element (gene) of the representation (chromosome)
❑ In general, small values are recommended for pm [0.001, 0.01]
Reproduction
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
13
❑ Some important points must be considered in the design of 
the mutation operator
❑ Ergodicity: mutation should allow every solution to be 
reached
❑ Validity: mutation should produce valid solutions. This is not 
always possible for constrained optimization problems
❑ Locality: mutation should produce minimal change
 When small changes are done on the genotype, the phenotype must reveal 
small changes. Hence, the evolutionary algorithm will carry out a 
meaningful search in the landscape of the problem
 Weak locality means small changes in the genotype lead to large changes 
in the phenotype
 For example, when a low quality solution is generated from a high quality 
one, this is called highly disruptive mutation
Reproduction
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
14
❑ Mutation is related to neighborhood operators of Smetaheuristics. Hence, the neighborhood structure 
definitions of traditional representations may be reused 
as mutation operators
 Mutation in binary representation: flip operator
 Mutation in discrete representation: changing the value 
of an element by another value of the alphabet
 Mutation in permutations: swapping, inversion, or 
insertion operators
Reproduction
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
15
❑ For real valued vectors, there are many distinct operators. 
For example: x’= x+m, where m is a random variable in 
the interval [–a, a]
❑ For Genetic Programming (GP) where parse trees are 
used as representations, some distinct forms of mutation 
can be defined as follows:
 Grow: terminal node replaced by a subtree
 Shrink: internal subtree replaced by a terminal node
 Switch: two subtrees are switched
 Cycle: a node is replaced by another with the same number of 
arguments
Reproduction
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
16
Reproduction
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
17
❑ Recombination or Crossover:
❑ The crossover operator is binary and sometimes n-ary
❑ The role of the crossover is to inherit some characteristics of the 
two parents to generate the offspring
❑ Some important points must be taken into account in the design of 
crossover
❑ Heritability: crossover should inherit genetic material from both 
parents. A crossover is respectful if the common decisions in both 
parents are preserved, and is assorting if the distance between the 
parents (p1
, p2
) and the offspring o is lower or equal to the distance 
between the parents
d(p1 ,o) ≤ d(p1 ,p2
) and d(p2 ,o) ≤ d(p1 ,p2
) 
❑ Validity: the crossover operator should produce valid solutions. This 
is not always possible for constrained optimization problems
Reproduction
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
18
❑ The crossover rate Pc
(Pc
 Є[0,1] )represents the proportion of 
parents on which a crossover operator will act
❑ The common rates are in the interval [0.45, 0.95]
❑ Some adaptive techniques for crossover rates may be used
❑ The most common types of crossover are:
❑ 1-point, 2-point, n-point crossover: where 1, 2, or n crossover 
sites are selected at random and the offspring are generated 
by interchanging the corresponding segments between the 
parents
❑ In the uniform crossover, each element of the offspring is 
selected randomly from either parent
Reproduction
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
19
Reproduction
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
20
Highly disruptive and non-heritable crossover 
Example: Project Assignment Example (Students to Projects)
❑ We have students:
 A = Ahmed
 B = Basma
 C = Charles
 D = Dana
❑ We want to assign students to project groups, where:
 Each group = one project team.
 A student can join multiple projects, but not appear twice in the same 
project.
Reproduction
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
21
Solution1:
Project 1: Ahmed 
Project 2: Basma, Charles 
Project 3: Ahmed, Dana
Solution 2:
Project 1: Charles 
Project 2: Ahmed, Dana 
Project 3: Basma, Charles
Parent 1 A | BC | AD
Parent 2 C | AD | BC
Child 1 A | AD | AD
Child 2 C | BC | BC
❑ This crossover is non-heritable since it does not preserve the 
genetic material of the parents (some participants have 
disappeared) and may be highly disruptive if it produces low 
quality solutions from good ones. 
Reproduction
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
22
❑ Applying traditional crossover to permutations will generate 
solutions that are not feasible (not permutations). Special 
permutation crossover has been designed as follows:
❑ Order Crossover: 
1. Two crossover points are randomly selected from parent 1
2. The part between the two points will be copied from parent 
1 to the offspring 
3. From parent 2, start at the second crossover point and pick 
the elements that are not already selected from parent 1
Reproduction
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
23
Reproduction
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
24
❑ Two-point Crossover: two points are randomly selected. 
The elements outside the selected points are inherited 
from one parent and the other elements are placed in the 
order of appearance in the other parent
2 8 1
Reproduction
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
25
❑ Partially Matched Crossover (PMX): two crossing sites are 
picked at random. These two points define a matching 
section that is used to perform position by position 
exchange operations
❑ For example
Parent 1: 9 8 4 | 5 6 7 | 1 3 2 10
Parent 2: 8 7 1 |2 3 10 | 9 5 4 6 
Child 1 : 9 8 4 |2 3 10| 1 6 5 7
Child 2 : 8 10 1| 5 6 7| 9 2 4 3
Replacement Strategies
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
26
❑ Replacement is concerned with the survivor selection from both 
the parent and the offspring populations
❑ The size of the population should remain fixed→ some individuals 
must be killed off
❑ The extreme replacement strategies are:
❑ Generational Replacement: offspring will completely replace parent 
population
❑ Steady-state replacement: at each generation only one offspring is 
generated. For instance, it replaces the worst individual of the 
parent population
❑ Between these two extremes, many replacement strategies can be 
applied by replacing a certain number or percentage of the old 
population
❑ Elitism always consists in selecting best individuals from the parents 
and the offspring
Parameters of EAs
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
27
❑ Mutation Probability: a large mutation probability will disrupt 
a given individual and the search may become random. 
Generally small values are recommended for mutation 
probability [0.001, 0.01]
❑ Crossover probability: is generally set from medium to large 
values [0.45, 0.95]
❑ Population Size: the larger the size of the population, the 
better is the convergence toward good solutions. However, 
the time complexity of the EAs grows linearly with the size of 
the population. A compromise must be found between the 
quality of the obtained solutions and the search time of the 
algorithm. In practice, the population size is usually between 
20 and 100
Scatter Search (SS)
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
28
❑ SS is a deterministic strategy that has been applied successfully to 
some combinatorial and continuous optimization problems
❑ SS combines solutions selected from a reference set to build others
❑ The method starts by generating a population (POP) of solutions 
satisfying the criteria of diversity and quality
❑ A reference set (RefSet) of moderate size (e.g. 10 solutions) is 
constructed from good solution in POP
❑ The selected solutions are combined (in a way similar to crossover) 
to provide starting solutions to an improvement procedure based 
on S-metaheuristic
❑ According the results produced by the improvement procedure the 
reference set is updated to incorporate both high quality and 
diversified solutions
❑ The process is repeated until a stopping criterion is satisfied
Scatter Search (SS)
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
29
Scatter Search (SS)
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
30
Scatter Search (SS)
Reference: Metaheuristics from Design to Implementation, El-Ghazali Talbi- Wiley, 2009
31
❑ Diversification generation method: generates a set of diverse initial 
solutions, e.g. using a greedy procedure
❑ Improvement method: transforms a trial solution into one or more 
enhanced solutions using any S-metaheuristic (e.g. local search)
❑ Reference set update method: must ensure diversity while keeping 
high quality solutions. 
❑ Subset generation method: operates on RefSet to generate a 
subset of solutions as a basis for creating combined solutions. It 
usually selects all subsets of size r (e.g. r=3). Its similar to selection 
mechanism in EA but it is deterministic rather than stochastic
❑ Solution combination method: is a generalization of the crossover 
operator where more than two individuals are recombined