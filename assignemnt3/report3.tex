\documentclass{article}

\usepackage{hyperref}

 
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{tabularx}
\usepackage{ragged2e}
\usepackage{booktabs} % For professional-looking tables
\usepackage{enumitem} % For custom list formatting
\usepackage{float} % For [H] placement of tables
\usepackage{multirow} % For multirow cells in tables

% Define argmin operator
\DeclareMathOperator*{\argmin}{arg\,min}

 \usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry} 
 
\begin{document}


\setlength{\parindent}{0cm}
%%  Declarations of your title page
\begin{titlepage}
 
\begin{center}
 
% Upper part of the page

\includegraphics[width=5cm]{figures/KSU_Logo.png}\\
\small King Saud University\\College of Computer and Information Sciences\\Department of Computer Science\\[2cm]



% Title
{\Huge \bfseries Selected Topics in Artificial Intelligence \par} 
\vspace{0.5cm} 
{\Huge \bfseries  CSC 569 \par} 
\vspace{1cm} 
{\Huge \bfseries Ant Colony Optimization for Graph Coloring \par} 
\vspace{1cm}
{ \large \bfseries Population-based Metaheuristic \par} 

% \vspace{0.4cm}  
%     {\Huge \bfseries Assignment 2: Single-solution based Metaheuristic to solve The Graph Coloring Problem (GCP) \par}

\vspace{2cm}
% Author and supervisor
\large \textit{By:}\\[0.3cm]
\large Mohammed Edris Mahdy \\
\large 446910613 \\
[0.5cm]
\large Mohammed Ahmed Ewida \\
\large 446910614 \\
[1cm]

\large  \textit{ Under the supervision of:}\\[0.3cm]
\large Prof. Manar Hosny    \\
[1cm]
% Submitted in partial fulfillment of the requirements \\
% for the Degree of Master in Artificial Intelligence at \\
% the Department of Computer Science, \\
% College of Computer and Information Sciences,\\
% King Saud University

\vfill
 
% Bottom of the page
{\large December 4, 2025 }
 
\end{center}
 
\end{titlepage}




 
    


\section{Problem Statement}

The \textbf{Graph Coloring Problem (GCP)} is formally defined for an undirected graph $G = (V, E)$, where $V$ represents the set of vertices and $E$ is the set of edges connecting these vertices \cite{Bessedik2005, Cadenas2023, MendezDiaz2014}. A $k$-coloring of $G$ is a function $C : V \to \{1, 2, \dots, k\}$ that assigns a color from a set of $k$ available colors to each vertex in $V$, subject to the constraint that any two adjacent vertices must be assigned different colors. Formally, for any edge $(u, v) \in E$, it must hold that $C(u) \neq C(v)$ \cite{Bessedik2005, Cadenas2023, Indumathi2021, Postigo2021}. The primary objective of the GCP is to find the minimum number of colors, $k$, required for a valid coloring, which is known as the chromatic number of $G$, denoted by $\chi(G)$ \cite{Bessedik2005, Indumathi2021}.

\subsection{Formal Problem Components}

\textbf{Input:}
\begin{itemize}
    \item An undirected graph $G = (V, E)$ where:
    \begin{itemize}
        \item $V = \{v_1, v_2, \dots, v_n\}$ is the set of vertices with $|V| = n$
        \item $E \subseteq V \times V$ is the set of edges with $|E| = m$
    \end{itemize}
    \item An initial number of colors $k$ (to be minimized)
\end{itemize}

\textbf{Output:}
\begin{itemize}
    \item A coloring function $C: V \to \{1, 2, \dots, k\}$ that assigns a color to each vertex
    \item The minimum number of colors $k^* = \chi(G)$ needed for a proper coloring
\end{itemize}

\textbf{Decision Variables:}
\begin{itemize}
    \item $C(v_i)$: The color assigned to vertex $v_i \in V$, where $C(v_i) \in \{1, 2, \dots, k\}$
\end{itemize}

\textbf{Constraints:}
\begin{enumerate}
    \item \textbf{Adjacent vertices constraint:} For all edges $(u, v) \in E$, adjacent vertices must have different colors:
    $$\forall (u, v) \in E: \quad C(u) \neq C(v)$$
    \item \textbf{Color range constraint:} Each vertex must be assigned exactly one color from the available color set:
    $$\forall v \in V: \quad C(v) \in \{1, 2, \dots, k\}$$
\end{enumerate}

\textbf{Objective Function:}
\begin{itemize}
    \item Minimize the number of colors used: $\min k$ subject to the constraints above
    \item Equivalently, minimize the conflict count $F(C)$ where:
    $$F(C) = \sum_{(u,v) \in E} \mathbb{I}(C(u) = C(v))$$
    where $\mathbb{I}$ is the indicator function that returns 1 if $C(u) = C(v)$ and 0 otherwise
    \item A solution is feasible (proper coloring) if and only if $F(C) = 0$
\end{itemize}

 
\section{Methodology (P-metaheuristic)}

This report implements a \textbf{population-based metaheuristic} (Ant Colony Optimization) to address the computational complexity of the GCP. ACO leverages collective intelligence of multiple agents to explore the solution space through constructive pheromone-guided building of solutions.

\subsection{Ant Colony Optimization (ACO)}
\textbf{Ant Colony Optimization (ACO)} is a nature-inspired population-based metaheuristic that mimics the foraging behavior of ants, which deposit pheromone trails to guide other ants toward good solutions \cite{Bessedik2005}. Unlike improvement-based methods like Tabu Search, ACO employs multiple artificial ants that work in parallel to construct complete solutions from scratch, eliminating dependency on initial solution quality.

\subsubsection{ACO Mechanism}
The ACO algorithm for graph coloring operates through the following key mechanisms:

\begin{itemize}
    \item \textbf{Pheromone Matrix:} A matrix $\tau[v][c]$ maintains pheromone levels for each node-color pair, initialized uniformly to 1.0. Higher pheromone values indicate historically successful color assignments. The matrix dynamically expands when more colors are needed during construction.
    
    \item \textbf{Constructive Solution Building:} Each ant constructs a complete valid coloring from scratch by:
    \begin{enumerate}
        \item Starting from a randomly assigned node
        \item Visiting remaining nodes in random order
        \item For each uncolored node, selecting a color probabilistically based on:
        \begin{itemize}
            \item \textbf{Pheromone level} ($\tau^{\alpha}$): Higher pheromone = more attractive
            \item \textbf{Heuristic information} ($\eta^{\beta}$): Preference for already-used colors to minimize total color count
        \end{itemize}
        \item Only considering valid colors (no conflicts with adjacent colored nodes)
    \end{enumerate}
    
    \item \textbf{Probabilistic Color Selection:} For a node $v$ with valid color set $C_v$, the probability of selecting color $c \in C_v$ is:
    $$P(c) = \frac{[\tau[v][c]]^{\alpha} \cdot [\eta[c]]^{\beta}}{\sum_{c' \in C_v} [\tau[v][c']]^{\alpha} \cdot [\eta[c']]^{\beta}}$$
    where $\eta[c] = 2.0$ if color $c$ is already used (intensification), else $\eta[c] = 1.0$ (diversification).
    
    \item \textbf{Pheromone Evaporation:} After all ants complete their solutions, pheromones decay globally by factor $(1-\rho)$:
    $$\tau[v][c] \leftarrow (1-\rho) \cdot \tau[v][c]$$
    This prevents unlimited accumulation and allows the algorithm to "forget" old, potentially sub-optimal patterns.
    
    \item \textbf{Pheromone Reinforcement:} The iteration-best solution receives pheromone deposit inversely proportional to its color count:
    $$\tau[v][c] \leftarrow \tau[v][c] + \frac{Q}{k_{best}}$$
    where $Q$ is the deposit intensity parameter and $k_{best}$ is the number of colors used. Better solutions (fewer colors) receive stronger reinforcement.
    
    \item \textbf{Parallel Ant Execution:} Multiple ants construct solutions concurrently using multi-threading, significantly improving computational efficiency while maintaining solution diversity through randomized starting nodes and visitation orders.
    
    \item \textbf{Global Best Tracking:} The algorithm maintains the best solution found across all iterations, returning the global optimum when terminated.
    
    \item \textbf{Early Stopping:} If no improvement is found for a specified patience period (as a fraction of total iterations), the algorithm terminates early to save computational resources.
\end{itemize}

\subsection{Algorithm Pseudocode}

The complete ACO algorithm for graph coloring is formalized below in two components: the main ACO loop and the single-ant construction process.

\vspace{1em}
\textbf{Algorithm 1: Ant Colony Optimization (ACO) for GCP}
\begin{enumerate}
    \item \textbf{Input:} Graph $G = (V, E)$, iterations $T$, ant count $m$, $\alpha$, $\beta$, $\rho$, $Q$, patience $p$.
    \item Initialize pheromone matrix $\tau[v][c] \leftarrow 1.0$ for all $v \in V$, $c \in \{1, \dots, k_{max}\}$.
    \item $S_{best} \leftarrow \text{None}$, $k_{best} \leftarrow \infty$, $no\_improve \leftarrow 0$.
    \item \textbf{For} $iter = 1$ \textbf{to} $T$ \textbf{Do}
    \item \hspace{2em} \textbf{// Parallel Ant Construction Phase}
    \item \hspace{2em} \textbf{For} $ant = 1$ \textbf{to} $m$ \textbf{Do (in parallel)}
    \item \hspace{4em} $S_{ant} \leftarrow $ ConstructSolution($G$, $\tau$, $\alpha$, $\beta$)
    \item \hspace{4em} $k_{ant} \leftarrow $ CountColors($S_{ant}$)
    \item \hspace{2em} \textbf{End For}
    \item \hspace{2em} \textbf{// Find Iteration-Best Solution}
    \item \hspace{2em} $S_{iter} \leftarrow \argmin_{ant} k_{ant}$, $k_{iter} \leftarrow \min_{ant} k_{ant}$
    \item \hspace{2em} \textbf{If} $k_{iter} < k_{best}$ \textbf{Then}
    \item \hspace{4em} $S_{best} \leftarrow S_{iter}$, $k_{best} \leftarrow k_{iter}$, $no\_improve \leftarrow 0$
    \item \hspace{2em} \textbf{Else}
    \item \hspace{4em} $no\_improve \leftarrow no\_improve + 1$
    \item \hspace{2em} \textbf{// Pheromone Update}
    \item \hspace{2em} $\tau[v][c] \leftarrow (1-\rho) \cdot \tau[v][c]$ for all $v, c$ \quad // Evaporation
    \item \hspace{2em} \textbf{For each} $(v, c) \in S_{iter}$ \textbf{Do}
    \item \hspace{4em} $\tau[v][c] \leftarrow \tau[v][c] + Q / k_{iter}$ \quad // Reinforcement
    \item \hspace{2em} \textbf{If} $no\_improve \geq p \cdot T$ \textbf{Then} \textbf{Break} \quad // Early stopping
    \item \textbf{End For}
    \item \textbf{Return} $S_{best}$, $k_{best}$
\end{enumerate}

\vspace{1em}
\textbf{Algorithm 2: ConstructSolution (Single Ant)}
\begin{enumerate}
    \item \textbf{Input:} Graph $G$, pheromone matrix $\tau$, parameters $\alpha$, $\beta$.
    \item $S \leftarrow \{\}$, $used\_colors \leftarrow \{\}$.
    \item $order \leftarrow $ RandomPermutation($V$) \quad // Random node visitation order
    \item \textbf{For each} $v \in order$ \textbf{Do}
    \item \hspace{2em} $neighbor\_colors \leftarrow \{S[u] : u \in N(v), u \in S\}$
    \item \hspace{2em} $valid\_colors \leftarrow \{c : c \notin neighbor\_colors\}$ \quad // No conflicts
    \item \hspace{2em} \textbf{If} $valid\_colors = \emptyset$ \textbf{Then} \quad // Expand color set
    \item \hspace{4em} Add new color to $\tau$ and $valid\_colors$
    \item \hspace{2em} \textbf{For each} $c \in valid\_colors$ \textbf{Do}
    \item \hspace{4em} $\eta[c] \leftarrow 2.0$ if $c \in used\_colors$ else $1.0$ \quad // Heuristic
    \item \hspace{4em} $score[c] \leftarrow [\tau[v][c]]^{\alpha} \cdot [\eta[c]]^{\beta}$
    \item \hspace{2em} $P[c] \leftarrow score[c] / \sum_{c'} score[c']$ \quad // Normalize probabilities
    \item \hspace{2em} $c_{chosen} \leftarrow $ SampleColor($valid\_colors$, $P$) \quad // Probabilistic selection
    \item \hspace{2em} $S[v] \leftarrow c_{chosen}$, $used\_colors \leftarrow used\_colors \cup \{c_{chosen}\}$
    \item \textbf{End For}
    \item \textbf{Return} $S$
\end{enumerate}







\section{Solution Representation, Objective Function, and Constraints}

\subsection{Solution Representation}
In ACO, a coloring solution is represented as a dictionary (mapping) where each key is a vertex and its value is the assigned color:
$$
\text{Solution} = \{v_1: c_1, v_2: c_2, \dots, v_{|V|}: c_{|V|}\}
$$
where $c_i \in \{1, 2, \dots, k\}$ represents the color assigned to vertex $v_i$. This representation allows efficient lookup and update operations during ant construction.

\subsection{Objective Function}
For ACO, the objective is to minimize the number of colors $k$ used in the solution while maintaining zero conflicts:
$$
\text{Minimize } k = |\{c : \exists v \in V, C(v) = c\}|
$$
subject to the constraint that $F(C) = 0$, where:
$$
F(C) = \sum_{(u,v) \in E} \mathbb{I}(C(u) = C(v))
$$
Unlike improvement-based methods (TS), ACO constructs only valid, conflict-free solutions from the start, so $F(C) = 0$ is guaranteed by design.

\subsection{Constraint Handling}
ACO uses a \textbf{Preserving Strategy} (constructive approach) where conflicts are prevented during solution construction rather than repaired afterward:
\begin{itemize}
    \item At each step, an ant only considers valid colors for a node (colors not used by any already-colored neighbors)
    \item If no valid color exists in the current color set, the pheromone matrix is dynamically expanded to accommodate a new color
    \item This guarantees that all constructed solutions are feasible ($F(C) = 0$) without requiring repair mechanisms
\end{itemize}

\subsection{Population Generation and Diversity}
\begin{itemize}
    \item \textbf{Initial Population:} Not applicable in traditional sense. ACO generates a new population of solutions at each iteration through parallel ant construction.
    
    \item \textbf{Ant Starting Nodes:} To ensure diverse exploration:
    \begin{itemize}
        \item If $m \leq |V|$: Each ant is assigned a unique random starting node
        \item If $m > |V|$: All nodes are covered first, then remaining ants are assigned to random nodes
    \end{itemize}
    
    \item \textbf{Node Visitation Order:} After the starting node, each ant visits remaining nodes in a random shuffled order, introducing stochastic variation across ants and iterations.
\end{itemize}

\subsection{Diversification and Intensification Strategies}
ACO balances exploration and exploitation through multiple complementary mechanisms:

\begin{itemize}
    \item \textbf{Intensification (Exploitation):}
    \begin{itemize}
        \item \textbf{Pheromone Reinforcement:} Iteration-best solutions deposit pheromones on their node-color pairs, biasing future ants toward historically successful assignments
        \item \textbf{Heuristic Preference:} The heuristic function $\eta[c]$ assigns higher values ($2.0$) to already-used colors, encouraging color reuse to minimize $k$
        \item \textbf{Alpha Parameter ($\alpha$):} Controls pheromone influence; higher $\alpha$ increases exploitation of learned patterns
    \end{itemize}
    
    \item \textbf{Diversification (Exploration):}
    \begin{itemize}
        \item \textbf{Pheromone Evaporation:} Global decay by factor $(1-\rho)$ prevents unlimited accumulation and allows forgetting of outdated patterns
        \item \textbf{Probabilistic Selection:} Color selection is stochastic rather than greedy, allowing exploration of sub-optimal paths that may lead to better global solutions
        \item \textbf{Random Node Ordering:} Each ant constructs solutions with different node visitation sequences, exploring diverse solution construction paths
        \item \textbf{Multiple Ants:} Parallel construction of $m$ solutions per iteration samples different regions of the solution space simultaneously
        \item \textbf{Beta Parameter ($\beta$):} Controls heuristic influence; higher $\beta$ increases exploitation, while lower values promote exploration
    \end{itemize}
\end{itemize}

\section{Motivation and Contribution}

\subsection{Motivation}
The GCP is $\text{NP}$-hard, meaning that finding the optimal chromatic number for large graphs is computationally infeasible using exact methods. \textbf{Ant Colony Optimization} is chosen as a population-based metaheuristic because:

\begin{itemize}
    \item \textbf{Constructive Approach:} ACO builds solutions from scratch rather than improving existing ones, eliminating dependency on initial solution quality.
    
    \item \textbf{Collective Intelligence:} Multiple ants explore the solution space in parallel, enabling simultaneous investigation of diverse solution construction paths.
    
    \item \textbf{Adaptive Learning:} Pheromone-based memory accumulates knowledge about successful color assignments over iterations, creating an adaptive bias toward high-quality solutions without rigid deterministic rules.
    
    \item \textbf{Balance of Exploration-Exploitation:} The combination of pheromone trails (exploitation), heuristic information (intensification), probabilistic selection (exploration), and evaporation (forgetting) provides natural mechanisms for balancing these competing objectives.
\end{itemize}

The comparison between ACO (population-based) and Tabu Search (single-solution) serves to illuminate the fundamental trade-offs between these two major metaheuristic paradigms for the GCP.

\subsection{Contribution}
This work implements a constructive ACO approach for graph coloring with dynamic pheromone matrix expansion and parallel ant execution (82 ants) using multi-threading. Comprehensive hyperparameter tuning via Optuna framework over 40 trials optimized 6 parameters ($\alpha=1.54$, $\beta=5.97$, $\rho=0.097$, $m=82$, $Q=1.30$, iterations=261). The study provides a three-way empirical comparison across Greedy, Tabu Search, and ACO on DIMACS benchmarks (250-1000 vertices, 50-90\% density), revealing that constructive methods avoid initial solution dependency but achieve higher color counts than improvement-based approaches, while population-based methods offer consistent performance across instances.

\section{Experimental Setup}

\subsection{Implementation Environment}
The model was implemented using the \textbf{Python} programming language (version 3.12) within both \textbf{Jupyter Notebook} and standalone Python scripts. Several key libraries were essential for this task:
\begin{itemize}
    \item \textbf{NetworkX:} Used for graph structure creation, manipulation, and analysis.
    \item \textbf{NumPy:} Utilized for efficient numerical operations, array management, and pheromone matrix operations.
    \item \textbf{Threading:} Python's built-in threading module for parallel ant execution.
    \item \textbf{Optuna:} Advanced hyperparameter optimization framework for systematic parameter tuning.
    \item \textbf{Pandas:} Data manipulation and analysis for results processing and statistical computations.
    \item \textbf{Matplotlib \& Seaborn:} Used for generating all visual aids, including comparison charts, convergence graphs, and optimization history plots.
\end{itemize}
All experiments were conducted on a cloud server running Ubuntu Linux (6.8.0-71-generic kernel) with an AMD EPYC processor (8 cores, 2.79 GHz base frequency) and 24 GB of RAM.

\subsection{Parameter Tuning}
An \textbf{automated hyperparameter optimization} strategy was employed using the Optuna framework. The optimization objective was to minimize the total number of colors across all tuning dataset instances while maintaining zero conflicts. The process involved:

\begin{itemize}
    \item \textbf{Optimization Framework:} Optuna's Tree-structured Parzen Estimator (TPE) sampler
    \item \textbf{Number of Trials:} 40 independent optimization trials
    \item \textbf{Parallel Execution:} 6 parallel workers (n\_jobs=6)
    \item \textbf{Tuning Dataset:} Single graph instance (gc\_500\_9) to reduce computational cost
    \item \textbf{Optimization Duration:} 46 hours wall-clock time (225 hours total computational time across all trials)
    \item \textbf{Objective:} Minimize sum of colors across all test instances
\end{itemize}

\begin{longtable}{|l|l|l|}
\hline
Parameter (Factor) & Search Range & Optimal Value \\
\hline
\endhead
\hline
Iterations ($T$) & [200, 500] & 261 \\
\hline
Alpha ($\alpha$) - Pheromone Importance & [0.5, 2.0] & 1.536 \\
\hline
Beta ($\beta$) - Heuristic Importance & [1.0, 10.0] & 5.966 \\
\hline
Rho ($\rho$) - Evaporation Rate & [0.01, 0.5] & 0.097 \\
\hline
Ant Count ($m$) & [20, 100] & 82 \\
\hline
Pheromone Deposit ($Q$) & [0.1, 5.0] & 1.299 \\
\hline
Patience Ratio & [0.3, 0.8] & 0.577 \\
\hline
\end{longtable}

\textbf{Parameter Descriptions:}
\begin{itemize}
    \item \textbf{Iterations ($T$):} Maximum number of iterations before termination. Optimal: 261 iterations.
    \item \textbf{Alpha ($\alpha$):} Controls influence of pheromone trails in probabilistic selection. Higher values increase exploitation of learned patterns. Optimal: 1.536.
    \item \textbf{Beta ($\beta$):} Controls influence of heuristic information (color reuse preference). Higher values increase intensification toward color minimization. Optimal: 5.966 (high value indicates strong preference for heuristic guidance).
    \item \textbf{Rho ($\rho$):} Pheromone evaporation rate. Higher values promote exploration by faster forgetting. Optimal: 0.097 (low value preserves historical knowledge longer).
    \item \textbf{Ant Count ($m$):} Number of parallel ants constructing solutions per iteration. More ants increase exploration breadth. Optimal: 82 ants.
    \item \textbf{Pheromone Deposit ($Q$):} Intensity of pheromone reinforcement for iteration-best solution. Optimal: 1.299.
    \item \textbf{Patience Ratio:} Fraction of total iterations to wait without improvement before early stopping. Optimal: 0.577 (approximately 150 iterations patience).
\end{itemize}

The extensive hyperparameter optimization process (Figure~\ref{fig:optuna_history}) was conducted over 46 hours using 6 parallel workers, executing 40 trials that accumulated 225 hours of total computational time. The optimization started with initial trials achieving 215 colors and progressively improved, ultimately converging on trial 19 with 200 colors as the best configuration—a 7\% improvement (15-color reduction). This optimization journey revealed critical insights into ACO's behavior for graph coloring. The tuning process demonstrated that \textbf{high beta} (strong heuristic influence) and \textbf{low rho} (slow evaporation) were essential for performance, fundamentally emphasizing intensification over diversification—a counterintuitive finding for a metaheuristic typically valued for exploration capabilities.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/history.png}
    \caption{Optuna optimization history over 40 trials}
    \label{fig:optuna_history}
\end{figure}

Deeper analysis through parameter slice plots (Figure~\ref{fig:optuna_slice}) and importance metrics (Figure~\ref{fig:optuna_importance}) unveils the underlying dynamics. The slice analysis reveals that \textbf{beta} (heuristic weight) exhibits a clear downward trend at higher values, indicating that stronger heuristic guidance consistently improves color minimization. Meanwhile, \textbf{iterations} demonstrate an optimal range around 250-300, beyond which diminishing returns occur. Interestingly, other parameters show scattered relationships, suggesting complex non-linear interactions that challenge simple parameter tuning. The importance analysis quantifies these observations: \textbf{iterations} and \textbf{beta} dominate ACO performance, while \textbf{rho} (evaporation rate) has surprisingly minimal impact. This hierarchy implies that for graph coloring, the algorithm benefits more from strong problem-specific heuristics and sufficient search time than from sophisticated pheromone dynamics—a finding that questions whether ACO's core mechanism (pheromone learning) is well-suited to this problem structure.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/slice.png}
    \caption{Parameter slice plot showing objective value relationships}
    \label{fig:optuna_slice}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/importances.png}
    \caption{Hyperparameter importance analysis}
    \label{fig:optuna_importance}
\end{figure}

The best trial configuration (trial 19) successfully produced a valid conflict-free coloring of the tuning instance gc\_500\_9, as visualized in Figure~\ref{fig:best_trial}. This visualization confirms that despite the constructive approach's limitations in minimizing colors, the pheromone-guided construction mechanism effectively maintains feasibility by avoiding conflicts. The coloring demonstrates clear neighborhood patterns where adjacent vertices consistently receive different colors, validating the algorithm's constraint satisfaction capability even if color minimization remains suboptimal.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/best_trial_graph_coloring.png}
    \caption{Best trial (Trial 19) graph coloring for gc\_500\_9}
    \label{fig:best_trial}
\end{figure}

\subsection{Datasets}
We use standardized \textbf{Benchmark Instances} from the DIMACS graph coloring library \cite{MendezDiaz2014} to ensure the generality of the results and enable comparison with existing literature.

\begin{longtable}{|l|l|l|l|l|}
\hline
Instance & Vertices ($|V|$) & Edges ($|E|$) & Density & Chromatic Number ($\chi(G)$, BKS) \\
\hline
\endhead
\hline
dsjc250.5 & 250 & 31,336 & 50.3\% & 28 \\
\hline
dsjc500.9 & 500 & 224,874 & 90.0\% & 126 \\
\hline
dsjc1000.5 & 1000 & 249,826 & 50.0\% & 85 \\
\hline
\end{longtable}

These instances were selected to represent diverse graph characteristics:
\begin{itemize}
    \item \textbf{dsjc250.5:} Medium-size, medium-density graph
    \item \textbf{dsjc500.9:} Medium-size, very high-density graph (hardest instance)
    \item \textbf{dsjc1000.5:} Large-size, medium-density graph
\end{itemize}

Each algorithm was executed 3 times per instance to assess statistical robustness and consistency.

 


\section{Results and Discussion}
 The results are compared against two baseline algorithms: \textbf{Greedy} (simple constructive heuristic) and \textbf{Tabu Search} (single-solution metaheuristic from Assignment 2).
\subsection{Performance Metrics}
Performance is evaluated using:
\begin{itemize}
    \item \textbf{Solution Quality ($k$):} The final number of colors used (primary metric).
    \item \textbf{Percent Deviation from BKS:} Calculated against the Best-Known Solution (chromatic number).
    $$
    \text{Deviation } (\%) = \frac{\text{Obtained Colors} - \text{BKS}}{\text{BKS}} \times 100
    $$
    \item \textbf{Robustness:} Measured by the standard deviation ($\sigma$) and the average result over \textbf{3 independent runs}.
    \item \textbf{Computational Effort:} Measured by the average run time in seconds.
    \item \textbf{Conflict Count:} Number of edges connecting same-colored vertices (all algorithms achieved zero conflicts).
\end{itemize}

\subsection{Comprehensive Three-Way Comparison}

The ACO algorithm's performance is evaluated against two baseline methods for comparative analysis: \textbf{Greedy} (simple constructive heuristic providing fast approximate solutions) and \textbf{Tabu Search} (the S-metaheuristic implemented in Assignment 2, representing state-of-the-art single-solution approach). Table 1 presents detailed performance statistics across all three algorithms.

\begin{longtable}{|l|l|l|l|l|l|l|}
\hline
\textbf{Instance} & \textbf{Algorithm} & \textbf{Best} & \textbf{Avg.} & \textbf{Std.} & \textbf{Avg. Time (s)} & \textbf{Dev. (\%)} \\
\hline
\endhead
\hline
\multirow{3}{*}{dsjc250.5} & Greedy & 42 & 42.0 & 0.00 & 0.04 & 50.0 \\
& Tabu Search & 34 & 34.7 & 0.58 & 925.7 & 21.4 \\
& \textbf{ACO} & \textbf{55} & \textbf{55.7} & \textbf{0.58} & \textbf{1134.4} & \textbf{96.4} \\
\hline
\multirow{3}{*}{dsjc500.9} & Greedy & 174 & 174.0 & 0.00 & 0.24 & 38.1 \\
& Tabu Search & 164 & 166.0 & 2.00 & 6730.9 & 30.2 \\
& \textbf{ACO} & \textbf{199} & \textbf{201.3} & \textbf{2.52} & \textbf{5853.5} & \textbf{57.9} \\
\hline
\multirow{3}{*}{dsjc1000.5} & Greedy & 125 & 125.0 & 0.00 & 0.73 & 47.1 \\
& Tabu Search & 124 & 124.7 & 0.58 & 10026.2 & 45.9 \\
& \textbf{ACO} & \textbf{226} & \textbf{227.0} & \textbf{1.00} & \textbf{13669.6} & \textbf{165.9} \\
\hline
\end{longtable}

\textbf{Table 1:} Comprehensive performance comparison across three algorithmic paradigms. Best-Known Solutions (BKS): dsjc250.5=28, dsjc500.9=126, dsjc1000.5=85.

The comparative performance analysis (Figures~\ref{fig:comparison_best} and~\ref{fig:comparison_avg}) reveals a striking pattern: ACO consistently underperforms both baseline methods across all test instances, challenging the expectation that metaheuristics should outperform simple constructive approaches. Examining best-case performance (Figure~\ref{fig:comparison_best}), ACO produces 58-166\% more colors than the best-known solutions, while Tabu Search achieves only 21-46\% deviation. More concerning, ACO even trails the deterministic Greedy algorithm on some instances, suggesting fundamental algorithmic limitations rather than mere parameter tuning issues.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/comparison_best_colors.png} 
    \caption{Best colors comparison across algorithms}
    \label{fig:comparison_best}
\end{figure}

The average performance over three runs (Figure~\ref{fig:comparison_avg}) exposes an additional scalability problem: the performance gap between ACO and Tabu Search widens dramatically as graph size increases. On dsjc250.5 (250 vertices), ACO uses approximately 56 colors versus TS's 35 colors—a 61\% increase. However, on dsjc1000.5 (1000 vertices), ACO requires 227 colors versus TS's 125 colors—an 82\% increase. This non-linear degradation indicates that ACO's population-based constructive approach struggles increasingly with larger problem instances, likely due to pheromone signal dilution across the expanding solution space. The consistency metrics further reveal that while ACO shows low standard deviation (indicating reproducible results), it reproducibly achieves poor solutions—consistency without quality provides little practical value.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/comparison_avg_colors.png}
    \caption{Average colors comparison (3 runs per algorithm)}
    \label{fig:comparison_avg}
\end{figure}

\subsection{Algorithm-by-Algorithm Analysis}

\subsubsection{Greedy Algorithm - Baseline Performance}
The Greedy algorithm serves as the fast constructive baseline:
\begin{itemize}
    \item \textbf{Speed:} Extremely fast execution (0.04-0.73 seconds), providing instant solutions.
    \item \textbf{Quality:} Moderate solution quality with 38-50\% deviation from BKS.
    \item \textbf{Consistency:} Perfect consistency (std=0) due to deterministic nature.
    \item \textbf{Use Case:} Ideal for rapid prototyping, initial solution generation, or when computational resources are severely constrained.
\end{itemize}

\subsubsection{Tabu Search - Best Solution Quality}
Tabu Search demonstrates superior optimization capability:
\begin{itemize}
    \item \textbf{Quality:} Consistently achieves best solution quality across all instances (21-46\% deviation from BKS).
    \item \textbf{Improvement:} 0.3-17.5\% better than Greedy, 17.5-45.1\% better than ACO in terms of color count.
    \item \textbf{Time Cost:} High computational cost (926-10,026 seconds), 10,000-40,000× slower than Greedy.
    \item \textbf{Robustness:} Good consistency (std 0.58-2.00) across multiple runs.
    \item \textbf{Mechanism:} Benefits from starting with Greedy solution and systematically improving through iterative color reduction strategy.
\end{itemize}

\subsubsection{ACO - Population-Based Approach}
ACO demonstrates distinct characteristics as a constructive population-based method:
\begin{itemize}
    \item \textbf{Quality:} Poorest solution quality among all three methods (58-167\% deviation from BKS).
    \item \textbf{Constructive Limitation:} Struggles with color minimization because it builds solutions without the benefit of initial feasible colorings or iterative improvement.
    \item \textbf{Time Efficiency:} Comparable to or better than TS (1134-13,670 seconds) despite parallel ant execution.
    \item \textbf{Consistency:} Moderate robustness (std 0.58-2.52) showing stable but sub-optimal convergence.
    \item \textbf{Scalability:} Performance degradation increases with graph size (167\% deviation on dsjc1000.5 vs 99\% on dsjc250.5).
\end{itemize}

\subsection{Detailed Discussion and Insights}

\subsubsection{Quality-Time Trade-off}
The experimental results demonstrate clear trade-offs between the three algorithmic paradigms, as illustrated in Figures \ref{fig:comparison_best}, \ref{fig:comparison_avg}, and \ref{fig:comparison_time}:
\begin{itemize}
    \item \textbf{Greedy:} Fastest but lowest quality - appropriate for time-critical applications.
    \item \textbf{Tabu Search:} Highest quality but most expensive - optimal when solution quality is paramount.
    \item \textbf{ACO:} Middle ground in time but poorest quality - demonstrates that population-based methods don't automatically outperform single-solution approaches.
\end{itemize}

\subsubsection{Computational Efficiency Analysis}
Despite using 82 parallel ants, ACO's computational performance (Figure~\ref{fig:comparison_time}) surprisingly matches Tabu Search's single-solution sequential approach rather than achieving the expected speedup from parallelization. The timing results show ACO is 23\% slower on dsjc250.5 (1134s vs 926s), 13\% faster on dsjc500.9 (5854s vs 6731s), and 36\% slower on dsjc1000.5 (13670s vs 10026s). This near-parity occurs because the algorithms operate on fundamentally different time-complexity trade-offs: ACO runs fewer iterations (261) but must execute 82 ant constructions per iteration with probabilistic color selection and pheromone updates, while TS runs many more iterations (7000 per color level) with cheaper deterministic move evaluations. The result is a troubling cost-benefit ratio—ACO consumes comparable computational resources to TS while delivering dramatically inferior solution quality (2-3× more colors). Greedy's extreme speed advantage (< 1 second) positions it as the clear winner when rapid approximate solutions suffice, while TS dominates when quality justifies computational investment.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/comparison_execution_time.png}
    \caption{Execution time comparison across algorithms}
    \label{fig:comparison_time}
\end{figure}

\subsubsection{Why ACO Underperforms}
While the empirical results clearly demonstrate ACO's underperformance, the underlying causes likely involve several interconnected factors, though definitive attribution remains uncertain:

\begin{enumerate}
    \item \textbf{Constructive Nature:} ACO builds solutions from scratch without leveraging feasible starting points. Unlike TS which begins with a ~40-color Greedy solution and reduces it to ~35 colors, ACO must discover good color assignments purely through pheromone learning. This fundamental difference may place ACO at a disadvantage, though it's unclear whether this alone accounts for the performance gap.
    
    \item \textbf{Local Construction:} Each ant appears to make locally optimal decisions during construction without global conflict minimization. TS, in contrast, has a global view of all conflicts and systematically eliminates them. However, it's possible that better pheromone accumulation or heuristic design could overcome this limitation.
    
    \item \textbf{Pheromone Sparsity:} With large color sets (50-200 colors), pheromone signals may become diluted across the matrix, potentially weakening learning effects. TS's tabu list directly prevents recently rejected moves without statistical dilution. That said, alternative pheromone representations (e.g., edge-color instead of node-color) might mitigate this issue.
\end{enumerate}

\subsubsection{Graph Characteristics Impact}
\begin{itemize}
    \item \textbf{Density Effect:} All algorithms struggle more with high-density graphs (dsjc500.9, 90\% density) where conflict constraints are tighter. However, ACO's degradation is most severe (58\% deviation vs 30\% for TS).
    
    \item \textbf{Size Scalability:} ACO's deviation increases dramatically with graph size (96\% → 166\% from 250 to 1000 vertices), while TS remains relatively stable (21\% → 46\%). This suggests ACO's pheromone learning becomes less effective on larger instances.
    
    \item \textbf{dsjc250.5 Anomaly:} Surprisingly, ACO performs worst on the smallest instance (96\% deviation), suggesting that the 82-ant population may be over-exploring on simpler graphs where focused intensification (TS) is more effective.
\end{itemize}

\subsubsection{Computational Efficiency Analysis}
Despite using 82 parallel ants, ACO's computational time is comparable to TS:
\begin{itemize}
    \item \textbf{dsjc250.5:} ACO is 23\% slower than TS (1134s vs 926s)
    \item \textbf{dsjc500.9:} ACO is 13\% faster than TS (5854s vs 6731s)
    \item \textbf{dsjc1000.5:} ACO is 36\% slower than TS (13670s vs 10026s)
\end{itemize}

This near-parity occurs because:
\begin{itemize}
    \item ACO runs fewer iterations (261) with many ants per iteration
    \item TS runs many more iterations (7000 per color level) with single-solution updates
    \item Both algorithms spend time on different operations: ACO on probabilistic selection and pheromone updates, TS on conflict counting and move evaluation
\end{itemize}

\subsection{Discussion}

The comparative analysis reveals distinct paradigm trade-offs. Greedy excels when speed is critical and moderate solution quality suffices (quick prototyping, real-time systems), while Tabu Search is preferred when solution quality is paramount and computational time is available (offline optimization, production systems with quality requirements). The current ACO implementation is not recommended for graph coloring in its present form, though it might become competitive with enhancements such as improved heuristics (degree-based, conflict-prediction), hybrid approaches using TS-quality solutions to initialize pheromones, local search post-processing, or alternative pheromone models (edge-color instead of node-color).

Fundamentally, population-based methods are not inherently superior to single-solution methods—problem structure determines paradigm suitability. Improvement-based methods like TS benefit from starting with feasible solutions, while constructive methods like ACO must learn from scratch. The effectiveness of metaheuristics depends heavily on problem-specific heuristics and operators; ACO's generic pheromone model may be insufficient for highly constrained problems like graph coloring. Ultimately, there is no universally best algorithm—the choice depends on specific requirements including time budget, quality needs, and problem characteristics.

\clearpage

\bibliographystyle{plain}
\bibliography{references}
\end{document}