\documentclass{article}

\usepackage{hyperref}

 
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{tabularx}
\usepackage{ragged2e}
\usepackage{booktabs} % For professional-looking tables
\usepackage{enumitem} % For custom list formatting
\usepackage{float} % For [H] placement of tables
\usepackage{multirow} % For multirow cells in tables

% Define argmin operator
\DeclareMathOperator*{\argmin}{arg\,min}

 \usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry} 
 
\begin{document}


\setlength{\parindent}{0cm}
%%  Declarations of your title page
\begin{titlepage}
 
\begin{center}
 
% Upper part of the page

\includegraphics[width=5cm]{figures/KSU_Logo.png}\\
\small King Saud University\\College of Computer and Information Sciences\\Department of Computer Science\\[2cm]



% Title
{\Huge \bfseries Selected Topics in Artificial Intelligence \par} 
\vspace{0.5cm} 
{\Huge \bfseries  CSC 569 \par} 
\vspace{1cm} 
{\Huge \bfseries Ant Colony Optimization for Graph Coloring \par} 
\vspace{1cm}
{ \large \bfseries Population-based Metaheuristic \par} 

% \vspace{0.4cm}  
%     {\Huge \bfseries Assignment 2: Single-solution based Metaheuristic to solve The Graph Coloring Problem (GCP) \par}

\vspace{2cm}
% Author and supervisor
\large \textit{By:}\\[0.3cm]
\large Mohammed Edris Mahdy \\
\large 446910613 \\
[0.5cm]
\large Mohammed Ahmed Ewida \\
\large 446910614 \\
[1cm]

\large  \textit{ Under the supervision of:}\\[0.3cm]
\large Prof. Manar Hosny    \\
[1cm]
% Submitted in partial fulfillment of the requirements \\
% for the Degree of Master in Artificial Intelligence at \\
% the Department of Computer Science, \\
% College of Computer and Information Sciences,\\
% King Saud University

\vfill
 
% Bottom of the page
{\large December 5, 2025 }
 
\end{center}
 
\end{titlepage}

\section{Introduction}

The Graph Coloring Problem (GCP) is an $\text{NP}$-hard combinatorial optimization problem with applications in scheduling, register allocation, and resource management. This report presents a comprehensive implementation and empirical evaluation of \textbf{Ant Colony Optimization (ACO)}, a population-based metaheuristic, for solving the GCP on DIMACS benchmark instances. The work systematically tunes ACO hyperparameters using Optuna's Tree-structured Parzen Estimator across 40 optimization trials and conducts a rigorous comparative analysis against Greedy heuristic and Tabu Search metaheuristic to elucidate the fundamental trade-offs between constructive population-based and improvement-based single-solution approaches.

The report is organized as follows: Section~\ref{sec:problem} defines the GCP formally. Section~\ref{sec:motivation} discusses the motivation for choosing ACO. Section~\ref{sec:methodology} presents the ACO methodology and algorithms. Section~\ref{sec:solution} describes solution representation and constraint handling. Section~\ref{sec:experimental} details the experimental setup and hyperparameter tuning. Section~\ref{sec:results} presents comparative results and analysis. Section~\ref{sec:conclusion} concludes with key findings and contributions.

\section{Problem Statement}
\label{sec:problem}

The \textbf{Graph Coloring Problem (GCP)} is formally defined for an undirected graph $G = (V, E)$, where $V$ represents the set of vertices and $E$ is the set of edges connecting these vertices. A coloring of $G$ is a function $C : V \to \mathbb{N}^+$ that assigns a color to each vertex in $V$, subject to the constraint that any two adjacent vertices must be assigned different colors. Formally, for any edge $(u, v) \in E$, it must hold that $C(u) \neq C(v)$. The primary objective of the GCP is to find the minimum number of colors required for a valid coloring, which is known as the chromatic number of $G$, denoted by $\chi(G)$\cite{bessedik_ant_2005,mendez_diaz_tabu_2014}.
\newline


\textbf{Input:}
\begin{itemize}
    \item An undirected graph $G = (V, E)$ where:
    \begin{itemize}
        \item $V = \{v_1, v_2, \dots, v_n\}$ is the set of vertices with $|V| = n$
        \item $E \subseteq V \times V$ is the set of edges with $|E| = m$
    \end{itemize}
\end{itemize}

\textbf{Output:}
\begin{itemize}
    \item A valid coloring function $C: V \to \mathbb{N}^+$ that assigns a color to each vertex
    \item The chromatic number $\chi(G)$, representing the minimum number of distinct colors used
\end{itemize}

\textbf{Decision Variables:}
\begin{itemize}
    \item $C(v_i)$: The color assigned to vertex $v_i \in V$, where $C(v_i) \in \mathbb{N}^+$
\end{itemize}

\textbf{Constraints:}
\begin{itemize}
    \item \textbf{Adjacent vertices constraint:} For all edges $(u, v) \in E$, adjacent vertices must have different colors:
    $$\forall (u, v) \in E: \quad C(u) \neq C(v)$$
\end{itemize}

\textbf{Objective Function:}
The ultimate goal is to find the chromatic number $\chi(G)$, the minimum number of distinct colors needed for a proper coloring:
\begin{itemize}
    \item Minimize the number of distinct colors used: $\min |\{C(v) : v \in V\}|$
    \item Subject to the adjacency constraint: $\forall (u, v) \in E: C(u) \neq C(v)$
    \item Equivalently, a solution is feasible if and only if the conflict count $F(C) = 0$, where:
    $$F(C) = \sum_{(u,v) \in E} \mathbb{I}(C(u) = C(v))$$
    and $\mathbb{I}$ is the indicator function that returns 1 if $C(u) = C(v)$ and 0 otherwise
\end{itemize}


\section{Motivation}
\label{sec:motivation}

The GCP is $\text{NP}$-hard, meaning that finding the optimal chromatic number for large graphs is computationally infeasible using exact methods \cite{postigo_comparative_2021}. \textbf{Ant Colony Optimization} is chosen as a population-based metaheuristic because:

\begin{itemize}
    \item \textbf{Constructive Approach:} ACO builds solutions from scratch rather than improving existing ones, eliminating dependency on initial solution quality.
    
    \item \textbf{Collective Intelligence:} Multiple ants explore the solution space in parallel, enabling simultaneous investigation of diverse solution construction paths.
    
    \item \textbf{Adaptive Learning:} Pheromone-based memory accumulates knowledge about successful color assignments over iterations, creating an adaptive bias toward high-quality solutions without rigid deterministic rules.
    
    \item \textbf{Balance of Exploration-Exploitation:} The combination of pheromone trails (exploitation), heuristic information (intensification), probabilistic selection (exploration), and evaporation (forgetting) provides natural mechanisms for balancing these competing objectives.
\end{itemize}



 
\section{Methodology}
\label{sec:methodology}

This section presents the Ant Colony Optimization algorithm design for the GCP, including its core mechanisms, probabilistic solution construction process, and parallel execution strategy.

\textbf{Ant Colony Optimization (ACO)} is a nature-inspired population-based metaheuristic that simulates ant foraging behavior through pheromone trail deposition and probabilistic path selection \cite{bessedik_ant_2005}. ACO employs multiple artificial ants that construct complete solutions in parallel, using accumulated pheromone information to guide the search process toward high-quality colorings.

\subsection{ACO Mechanism}
The ACO algorithm for graph coloring operates through the following key mechanisms:

\begin{itemize}
    \item \textbf{Pheromone Matrix:} A matrix $\tau[v][c]$ maintains pheromone levels for each node-color pair, initialized uniformly to 1.0. Higher pheromone values indicate historically successful color assignments. The matrix dynamically expands when more colors are needed during construction.
    
    \item \textbf{Constructive Solution Building:} Each ant constructs a complete valid coloring from scratch by:
    \begin{enumerate}
        \item Starting from its assigned starting node (distributed to ensure coverage)
        \item Visiting remaining nodes in shuffled random order for diversity
        \item For each uncolored node, selecting a color probabilistically based on:
        \begin{itemize}
            \item \textbf{Pheromone level} ($\tau^{\alpha}$): Higher pheromone = more attractive
            \item \textbf{Heuristic information} ($\eta^{\beta}$): Preference for already-used colors to minimize total color count
        \end{itemize}
        \item Only considering valid colors (no conflicts with adjacent colored nodes)
    \end{enumerate}
    
    \item \textbf{Probabilistic Color Selection:} For a node $v$ with valid color set $C_v$, the probability of selecting color $c \in C_v$ is:
    $$P(c) = \frac{[\tau[v][c]]^{\alpha} \cdot [\eta[c]]^{\beta}}{\sum_{c' \in C_v} [\tau[v][c']]^{\alpha} \cdot [\eta[c']]^{\beta}}$$
    where $\eta[c] = 2.0$ if color $c$ is already used (intensification), else $\eta[c] = 1.0$ (diversification).
    
    \item \textbf{Pheromone Evaporation:} After all ants complete their solutions, pheromones decay globally by factor $(1-\rho)$:
    $$\tau[v][c] \leftarrow (1-\rho) \cdot \tau[v][c]$$
    This prevents unlimited accumulation and allows the algorithm to "forget" old, potentially sub-optimal patterns.
    
    \item \textbf{Pheromone Reinforcement:} The iteration-best solution receives pheromone deposit inversely proportional to its color count:
    $$\tau[v][c] \leftarrow \tau[v][c] + \frac{Q}{k_{best}}$$
    where $Q$ is the deposit intensity parameter and $k_{best}$ is the number of colors used. Better solutions (fewer colors) receive stronger reinforcement.
    
    \item \textbf{Parallel Ant Execution:} Multiple ants construct solutions concurrently using multi-threading, significantly improving computational efficiency while maintaining solution diversity through randomized starting nodes and visitation orders. When ant count exceeds node count, all nodes are assigned first to ensure full graph coverage, with remaining ants randomly assigned.
    
    \item \textbf{Global Best Tracking:} The algorithm maintains the best solution found across all iterations, returning the global optimum when terminated.
    
    \item \textbf{Early Stopping:} If no improvement is found for a specified patience period (as a fraction of total iterations), the algorithm terminates early to save computational resources.
\end{itemize}

\subsection{Algorithm Pseudocode}

The ACO algorithm for graph coloring is formalized in two components: the main iteration loop (Algorithm 1) and the single-ant solution construction procedure (Algorithm 2).

\vspace{1em}
\textbf{Algorithm 1: Ant Colony Optimization (ACO) for GCP}
\begin{enumerate}
    \item \textbf{Input:} Graph $G = (V, E)$, iterations $T$, ant count $m$, $\alpha$, $\beta$, $\rho$, $Q$, patience $p$.
    \item Initialize pheromone matrix $\tau[v][c] \leftarrow 1.0$ for all $v \in V$, $c \in \{1, \dots, k_{max}\}$.
    \item $S_{best} \leftarrow \text{None}$, $k_{best} \leftarrow \infty$, $no\_improve \leftarrow 0$.
    \item \textbf{For} $iter = 1$ \textbf{to} $T$ \textbf{Do}
    \item \hspace{2em} \textbf{// Parallel Ant Construction Phase}
    \item \hspace{2em} \textbf{For} $ant = 1$ \textbf{to} $m$ \textbf{Do (in parallel)}
    \item \hspace{4em} $S_{ant} \leftarrow $ ConstructSolution($G$, $\tau$, $\alpha$, $\beta$)
    \item \hspace{4em} $k_{ant} \leftarrow $ CountColors($S_{ant}$)
    \item \hspace{2em} \textbf{End For}
    \item \hspace{2em} \textbf{// Find Iteration-Best Solution}
    \item \hspace{2em} $S_{iter} \leftarrow \argmin_{ant} k_{ant}$, $k_{iter} \leftarrow \min_{ant} k_{ant}$
    \item \hspace{2em} \textbf{If} $k_{iter} < k_{best}$ \textbf{Then}
    \item \hspace{4em} $S_{best} \leftarrow S_{iter}$, $k_{best} \leftarrow k_{iter}$, $no\_improve \leftarrow 0$
    \item \hspace{2em} \textbf{Else}
    \item \hspace{4em} $no\_improve \leftarrow no\_improve + 1$
    \item \hspace{2em} \textbf{// Pheromone Update}
    \item \hspace{2em} $\tau[v][c] \leftarrow (1-\rho) \cdot \tau[v][c]$ for all $v, c$ \quad // Evaporation
    \item \hspace{2em} \textbf{For each} $(v, c) \in S_{iter}$ \textbf{Do}
    \item \hspace{4em} $\tau[v][c] \leftarrow \tau[v][c] + Q / k_{iter}$ \quad // Reinforcement
    \item \hspace{2em} \textbf{If} $no\_improve \geq p \cdot T$ \textbf{Then} \textbf{Break} \quad // Early stopping
    \item \textbf{End For}
    \item \textbf{Return} $S_{best}$, $k_{best}$
\end{enumerate}

\vspace{1em}
\textbf{Algorithm 2: ConstructSolution (Single Ant)}
\begin{enumerate}
    \item \textbf{Input:} Graph $G$, pheromone matrix $\tau$, parameters $\alpha$, $\beta$, starting node $v_{start}$.
    \item $S \leftarrow \{\}$, $used\_colors \leftarrow \{\}$.
    \item $order \leftarrow [v_{start}]$ \quad // Start from assigned node
    \item $remaining \leftarrow V \setminus \{v_{start}\}$
    \item Shuffle($remaining$) \quad // Randomize order of remaining nodes
    \item $order \leftarrow order + remaining$ \quad // Append shuffled nodes
    \item \textbf{For each} $v \in order$ \textbf{Do}
    \item \hspace{2em} $neighbor\_colors \leftarrow \{S[u] : u \in N(v), u \in S\}$
    \item \hspace{2em} $valid\_colors \leftarrow \{c : c \notin neighbor\_colors\}$ \quad // No conflicts
    \item \hspace{2em} \textbf{If} $valid\_colors = \emptyset$ \textbf{Then} \quad // Expand color set
    \item \hspace{4em} Add new color to $\tau$ and $valid\_colors$
    \item \hspace{2em} \textbf{For each} $c \in valid\_colors$ \textbf{Do}
    \item \hspace{4em} $\eta[c] \leftarrow 2.0$ if $c \in used\_colors$ else $1.0$ \quad // Heuristic
    \item \hspace{4em} $score[c] \leftarrow [\tau[v][c]]^{\alpha} \cdot [\eta[c]]^{\beta}$
    \item \hspace{2em} $P[c] \leftarrow score[c] / \sum_{c'} score[c']$ \quad // Normalize probabilities
    \item \hspace{2em} $c_{chosen} \leftarrow $ SampleColor($valid\_colors$, $P$) \quad // Probabilistic selection
    \item \hspace{2em} $S[v] \leftarrow c_{chosen}$, $used\_colors \leftarrow used\_colors \cup \{c_{chosen}\}$
    \item \textbf{End For}
    \item \textbf{Return} $S$
\end{enumerate}







\section{Solution Representation, Objective Function, and Constraints}
\label{sec:solution}

\subsection{Solution Representation}
A coloring solution is represented as a dictionary mapping each vertex to its assigned color:
$$
\text{Solution} = \{v_1: c_1, v_2: c_2, \dots, v_{|V|}: c_{|V|}\}
$$
where $c_i \in \{1, 2, \dots, k\}$ represents the color assigned to vertex $v_i$. This representation allows efficient lookup and update operations during ant construction.

\subsection{Objective Function}
The objective is to minimize the number of colors $k$ used in the solution:
$$
\text{Minimize } k = |\{c : \exists v \in V, C(v) = c\}|
$$
subject to the adjacency constraint $\forall (u,v) \in E: C(u) \neq C(v)$. ACO's constructive approach guarantees feasibility by design, as ants only select colors that produce zero conflicts with already-colored neighbors.

\subsection{Constraint Handling}
ACO uses a \textbf{Preserving Strategy} (constructive approach) where conflicts are prevented during solution construction rather than repaired afterward:
\begin{itemize}
    \item At each step, an ant only considers valid colors for a node (colors not used by any already-colored neighbors)
    \item If no valid color exists in the current color set, the pheromone matrix is dynamically expanded to accommodate a new color
    \item This guarantees that all constructed solutions are feasible ($F(C) = 0$) without requiring repair mechanisms
\end{itemize}

\subsection{Population Generation and Diversity}
\begin{itemize}
    \item \textbf{Population per Iteration:} ACO generates a new population of solutions at each iteration through parallel ant construction.
    
    \item \textbf{Ant Starting Nodes:} To ensure diverse exploration:
    \begin{itemize}
        \item If $m \leq |V|$: Each ant is assigned a unique random starting node
        \item If $m > |V|$: All nodes are covered first, then remaining ants are assigned to random nodes
    \end{itemize}
    
    \item \textbf{Node Visitation Order:} After the starting node, each ant visits remaining nodes in a random shuffled order, introducing stochastic variation across ants and iterations.
\end{itemize}

\subsection{Diversification and Intensification Strategies}
ACO balances exploration and exploitation through multiple complementary mechanisms:

\begin{itemize}
    \item \textbf{Intensification (Exploitation):}
    \begin{itemize}
        \item Pheromone reinforcement from iteration-best solutions
        \item Alpha parameter ($\alpha$) controls pheromone influence weight
        \item Heuristic preference ($\eta[c] = 2.0$) for reusing existing colors
    \end{itemize}
    
    \item \textbf{Diversification (Exploration):}
    \begin{itemize}
        \item Pheromone evaporation by factor $(1-\rho)$ to prevent premature convergence
        \item Beta parameter ($\beta$) controls heuristic influence weight
        \item Probabilistic color selection using roulette wheel sampling
        \item Random node visitation ordering per ant
        \item Parallel construction by $m$ ants per iteration
    \end{itemize}
\end{itemize}

\section{Experimental Setup}
\label{sec:experimental}

\subsection{Implementation Environment}
The model was implemented using the \textbf{Python} programming language (version 3.12) within both \textbf{Jupyter Notebook} and standalone Python scripts. Several key libraries were essential for this task:
\begin{itemize}
    \item \textbf{NetworkX:} Used for graph structure creation, manipulation, and analysis.
    \item \textbf{NumPy:} Utilized for efficient numerical operations, array management, and pheromone matrix operations.
    \item \textbf{Threading:} Python's built-in threading module for parallel ant execution.
    \item \textbf{Optuna:} Advanced hyperparameter optimization framework for systematic parameter tuning.
    \item \textbf{Pandas:} Data manipulation and analysis for results processing and statistical computations.
    \item \textbf{Matplotlib \& Seaborn:} Used for generating all visual aids, including comparison charts, convergence graphs, and optimization history plots.
\end{itemize}
All experiments were conducted on a cloud server running Ubuntu Linux (6.8.0-71-generic kernel) with an AMD EPYC processor (8 cores, 2.79 GHz base frequency) and 24 GB of RAM.

\subsection{Parameter Tuning}
An \textbf{automated hyperparameter optimization} strategy was employed using the Optuna framework. The optimization objective was to minimize the number of colors on the tuning graph while maintaining zero conflicts. The process involved:

\begin{itemize}
    \item \textbf{Optimization Framework:} Optuna's Tree-structured Parzen Estimator (TPE) sampler
    \item \textbf{Number of Trials:} 40 independent optimization trials
    \item \textbf{Parallel Execution:} 6 parallel workers (n\_jobs=6)
    \item \textbf{Tuning Dataset:} Single graph instance (gc\_500\_9) to reduce computational cost
    \item \textbf{Optimization Duration:} 46 hours wall-clock time (225 hours total computational time across all trials)
    \item \textbf{Objective:} Minimize sum of colors across all test instances
\end{itemize}

The optimized parameter values are presented in Table~\ref{tab:hyperparameters}.
\begin{longtable}{|l|l|l|}
\caption{ACO Hyperparameter Optimization Results}
\label{tab:hyperparameters}\\
\hline
Parameter (Factor) & Search Range & Optimal Value \\
\hline
\endhead
\hline
Iterations ($T$) & [200, 500] & 261 \\
\hline
Alpha ($\alpha$) - Pheromone Importance & [0.5, 2.0] & 1.536 \\
\hline
Beta ($\beta$) - Heuristic Importance & [1.0, 10.0] & 5.966 \\
\hline
Rho ($\rho$) - Evaporation Rate & [0.01, 0.5] & 0.097 \\
\hline
Ant Count ($m$) & [20, 100] & 82 \\
\hline
Pheromone Deposit ($Q$) & [0.1, 5.0] & 1.299 \\
\hline
Patience Ratio & [0.3, 0.8] & 0.577 \\
\hline
\end{longtable}

\textbf{Parameter Descriptions:}
\begin{itemize}
    \item \textbf{Iterations ($T$):} Maximum number of iterations before termination. Optimal: 261 iterations.
    \item \textbf{Alpha ($\alpha$):} Controls influence of pheromone trails in probabilistic selection. Higher values increase exploitation of learned patterns. Optimal: 1.536.
    \item \textbf{Beta ($\beta$):} Controls influence of heuristic information (color reuse preference). Higher values increase intensification toward color minimization. Optimal: 5.966 (high value indicates strong preference for heuristic guidance).
    \item \textbf{Rho ($\rho$):} Pheromone evaporation rate. Higher values promote exploration by faster forgetting. Optimal: 0.097 (low value preserves historical knowledge longer).
    \item \textbf{Ant Count ($m$):} Number of parallel ants constructing solutions per iteration. More ants increase exploration breadth. Optimal: 82 ants.
    \item \textbf{Pheromone Deposit ($Q$):} Intensity of pheromone reinforcement for iteration-best solution. Optimal: 1.299.
    \item \textbf{Patience Ratio:} Fraction of total iterations to wait without improvement before early stopping. Optimal: 0.577 (approximately 150 iterations patience).
\end{itemize}

The hyperparameter optimization process (Figure~\ref{fig:optuna_history}) executed 40 trials over 46 hours using 6 parallel workers. Trial 19 achieved the best configuration with 200 colors, representing a 7\% improvement over initial trials. The optimization revealed that high beta ($\beta=5.97$) and low rho ($\rho=0.097$) values were critical, indicating that strong heuristic guidance and slow pheromone decay are more beneficial than aggressive exploration for this problem.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/history.png}
    \caption{Optuna optimization history over 40 trials}
    \label{fig:optuna_history}
\end{figure}

Parameter slice plots (Figure~\ref{fig:optuna_slice}) and importance analysis (Figure~\ref{fig:optuna_importance}) provide deeper insights. Beta exhibits a clear downward trend at higher values, while iterations show an optimal range around 250-300. The importance analysis reveals that iterations and beta dominate performance, while rho has minimal impact. This suggests that sufficient search time and strong heuristic guidance contribute more to solution quality than pheromone dynamics for this problem.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/slice.png}
    \caption{Parameter slice plot showing objective value relationships}
    \label{fig:optuna_slice}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{figures/importances.png}
    \caption{Hyperparameter importance analysis}
    \label{fig:optuna_importance}
\end{figure}

The best trial configuration (trial 19) produced a conflict-free coloring of the tuning instance gc\_500\_9 with 200 colors, as visualized in Figure~\ref{fig:best_trial}. The visualization confirms that adjacent vertices receive different colors, validating the algorithm's constraint satisfaction capability.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/best_trial_graph_coloring.png}
    \caption{Best trial (Trial 19) graph coloring for gc\_500\_9}
    \label{fig:best_trial}
\end{figure}

\subsection{Datasets}
We use standardized \textbf{Benchmark Instances} from the DIMACS graph coloring library to ensure the generality of the results and enable comparison with existing literature. The characteristics of the selected test instances are shown in Table~\ref{tab:datasets}.

\begin{longtable}{|l|l|l|l|l|}
\caption{DIMACS Benchmark Instances Characteristics}
\label{tab:datasets}\\
\hline
Instance & Vertices ($|V|$) & Edges ($|E|$) & Density & Chromatic Number ($\chi(G)$, BKS) \\
\hline
\endhead
\hline
dsjc250.5 & 250 & 31,336 & 50.3\% & 28 \\
\hline
dsjc500.9 & 500 & 224,874 & 90.0\% & 126 \\
\hline
dsjc1000.5 & 1000 & 249,826 & 50.0\% & 85 \\
\hline
\end{longtable}

As detailed in Table~\ref{tab:datasets}, these instances were selected to represent diverse graph characteristics:
\begin{itemize}
    \item \textbf{dsjc250.5:} Medium-size, medium-density graph
    \item \textbf{dsjc500.9:} Medium-size, very high-density graph (hardest instance)
    \item \textbf{dsjc1000.5:} Large-size, medium-density graph
\end{itemize}

Each algorithm was executed 3 times per instance to assess statistical robustness and consistency.

 


\section{Results and Discussion}
\label{sec:results}

ACO performance is evaluated against two baselines: Greedy (constructive heuristic) and Tabu Search (improvement-based metaheuristic). Performance metrics include solution quality (color count), deviation from Best-Known Solutions (BKS), robustness (standard deviation across 3 runs), and computational time. Deviation is calculated as: $(\text{colors} - \text{BKS}) / \text{BKS} \times 100\%$.

\subsection{Comparative Performance Results}

Table~\ref{tab:performance_comparison} presents detailed performance statistics across all three algorithms.

\begin{longtable}{|l|l|l|l|l|l|l|l|}
\caption{Comparative Performance Analysis Across Three Algorithms}
\label{tab:performance_comparison}\\
\hline
\textbf{Instance} & \textbf{BKS} & \textbf{Algorithm} & \textbf{Best} & \textbf{Avg.} & \textbf{Std.} & \textbf{Avg. Time (s)} & \textbf{Dev. (\%)} \\
\hline
\endhead
\hline
\multirow{3}{*}{dsjc250.5} & \multirow{3}{*}{28} & Greedy & 42 & 42.0 & 0.00 & 0.04 & 50.0 \\
& & Tabu Search & 34 & 34.7 & 0.58 & 925.7 & 21.4 \\
& & \textbf{ACO} & \textbf{55} & \textbf{55.7} & \textbf{0.58} & \textbf{1134.4} & \textbf{96.4} \\
\hline
\multirow{3}{*}{dsjc500.9} & \multirow{3}{*}{126} & Greedy & 174 & 174.0 & 0.00 & 0.24 & 38.1 \\
& & Tabu Search & 164 & 166.0 & 2.00 & 6730.9 & 30.2 \\
& & \textbf{ACO} & \textbf{199} & \textbf{201.3} & \textbf{2.52} & \textbf{5853.5} & \textbf{57.9} \\
\hline
\multirow{3}{*}{dsjc1000.5} & \multirow{3}{*}{85} & Greedy & 125 & 125.0 & 0.00 & 0.73 & 47.1 \\
& & Tabu Search & 124 & 124.7 & 0.58 & 10026.2 & 45.9 \\
& & \textbf{ACO} & \textbf{226} & \textbf{227.0} & \textbf{1.00} & \textbf{13669.6} & \textbf{165.9} \\
\hline
\end{longtable}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/comparison_best_colors.png} 
    \caption{Best colors comparison across algorithms}
    \label{fig:comparison_best}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/comparison_avg_colors.png}
    \caption{Average colors comparison (3 runs per algorithm)}
    \label{fig:comparison_avg}
\end{figure}

The comparative performance analysis (Figures~\ref{fig:comparison_best} and~\ref{fig:comparison_avg}) reveals a striking pattern: ACO consistently underperforms both baseline methods across all test instances, challenging the expectation that metaheuristics should outperform simple constructive approaches. Examining best-case performance (Figure~\ref{fig:comparison_best}), ACO produces 58-166\% more colors than the best-known solutions, while Tabu Search achieves only 21-46\% deviation. More concerning, ACO even trails the deterministic Greedy algorithm on some instances, suggesting fundamental algorithmic limitations rather than mere parameter tuning issues.

The average performance over three runs (Figure~\ref{fig:comparison_avg}) exposes an additional scalability problem: the performance gap between ACO and Tabu Search widens dramatically as graph size increases. On dsjc250.5 (250 vertices), ACO uses approximately 56 colors versus TS's 35 colors—a 61\% increase. However, on dsjc1000.5 (1000 vertices), ACO requires 227 colors versus TS's 125 colors—an 82\% increase. This non-linear degradation indicates that ACO's population-based constructive approach struggles increasingly with larger problem instances, likely due to pheromone signal fragmentation across the expanding solution space. The consistency metrics further reveal that while ACO shows low standard deviation (indicating reproducible results), it reproducibly achieves poor solutions—consistency without quality provides little practical value.

The results reveal distinct performance profiles: Greedy achieves extremely fast execution (0.04-0.73 seconds) with 38-50\% deviation from BKS. Tabu Search demonstrates superior solution quality (21-46\% deviation) at high computational cost (926-10,026 seconds). ACO produces the poorest solutions (58-167\% deviation) despite comparable execution time to Tabu Search (1134-13,670 seconds), with performance degrading as graph size increases.



\subsection{Computational Efficiency}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/comparison_execution_time.png}
    \caption{Execution time comparison across algorithms}
    \label{fig:comparison_time}
\end{figure}

Despite using 82 parallel ants, ACO's execution time (Figure~\ref{fig:comparison_time}) is comparable to Tabu Search's sequential approach. This occurs because ACO runs fewer iterations (261) with expensive per-iteration operations (82 probabilistic constructions plus pheromone updates), while TS executes more iterations (7000 per color level) with cheaper deterministic move evaluations. The result is an unfavorable cost-benefit ratio: ACO consumes similar computational resources to TS while delivering inferior solution quality (2-3× more colors).

ACO's underperformance stems from several factors: (1) constructive approach without initialization from feasible solutions, unlike TS which improves from Greedy starting points; (2) local construction decisions without global conflict visibility; (3) pheromone signal fragmentation across large color sets (50-200 colors). Graph characteristics analysis shows ACO's deviation increases with size (96\% → 166\% for 250-1000 vertices) while TS remains stable (21\% → 46\%), indicating scalability limitations.

The comparative analysis reveals distinct algorithmic trade-offs: Greedy excels when speed is critical (< 1 second, 38-50\% deviation), Tabu Search delivers superior quality when time permits (926-10,026 seconds, 21-46\% deviation), while ACO underperforms both approaches (1134-13,670 seconds, 58-167\% deviation). The results demonstrate that problem structure determines paradigm suitability \cite{cadenas_comparative_2023}—improvement-based methods benefit from feasible initialization, while constructive approaches must learn from scratch. The effectiveness of metaheuristics depends heavily on problem-specific heuristics rather than algorithmic category alone.

\section{Conclusion}
\label{sec:conclusion}

This work presents a comprehensive implementation and empirical evaluation of Ant Colony Optimization for graph coloring using parallel ant execution and systematic hyperparameter optimization via Optuna (40 trials, 6 parameters). Comparative analysis on DIMACS benchmarks reveals that ACO's constructive population-based approach underperforms both Greedy heuristic and Tabu Search metaheuristic (58-167\% deviation vs. 21-46\% for TS) despite comparable computational cost. The results demonstrate that algorithmic paradigm alone does not guarantee performance—problem structure, initialization strategies, and heuristic design critically determine metaheuristic effectivenes. For graph coloring, improvement-based methods that leverage feasible starting solutions outperform constructive approaches that build solutions from scratch. Future work should investigate hybrid approaches combining ACO's population-based search with local improvement operators, degree-based construction heuristics, or alternative pheromone models tailored to graph coloring constraints.

\clearpage

\bibliographystyle{plain}
\bibliography{references}
\end{document}