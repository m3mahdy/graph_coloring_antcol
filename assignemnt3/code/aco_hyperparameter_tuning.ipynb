{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca71261",
   "metadata": {},
   "source": [
    "# ACO Hyperparameter Tuning for Graph Coloring Problem\n",
    "\n",
    "This notebook performs hyperparameter tuning for Ant Colony Optimization (ACO) algorithm applied to the Graph Coloring Problem using Optuna.\n",
    "\n",
    "## Workflow\n",
    "1. **Environment Setup**: Detect execution environment (Colab/Local) and configure paths\n",
    "2. **Parameter Configuration**: Define hyperparameter search space\n",
    "3. **Optimization**: Run Optuna tuner with objective function\n",
    "4. **Testing**: Evaluate best parameters on testing dataset\n",
    "5. **Visualization**: Generate and save performance plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a0f0d5",
   "metadata": {},
   "source": [
    "## 1. Environment Detection and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ccd402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Google Colab: False\n",
      "Local environment detected. Using local paths.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Check if running in Google Colab environment\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "print(f\"Running in Google Colab: {IS_COLAB}\")\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"Colab environment detected. Will mount Google Drive.\")\n",
    "    # Mount Google Drive if running in Colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"Google Drive mounted successfully at /content/drive\")\n",
    "else:\n",
    "    print(\"Local environment detected. Using local paths.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41857a60",
   "metadata": {},
   "source": [
    "## 2. Path Configuration\n",
    "\n",
    "Configure paths for data, studies, results, and figures based on the execution environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628428d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Path: /Users/mahdy/projects/meta_graph_coloring_antcol/assignemnt3\n",
      "Code Path: /Users/mahdy/projects/meta_graph_coloring_antcol/assignemnt3/code\n",
      "Data Root: /Users/mahdy/projects/meta_graph_coloring_antcol/assignemnt3/data\n",
      "\n",
      "Path verification: OK\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Configure base paths based on environment\n",
    "if IS_COLAB:\n",
    "    # Update this path to match your Google Drive structure\n",
    "    BASE_PATH = Path('/content/drive/MyDrive/meta_graph_coloring_antcol/assignemnt3')\n",
    "    CODE_PATH = BASE_PATH / 'code'\n",
    "    # Add code path to system path for imports\n",
    "    sys.path.insert(0, str(CODE_PATH))\n",
    "else:\n",
    "    # Local environment paths\n",
    "    BASE_PATH = Path('/Users/mahdy/projects/meta_graph_coloring_antcol/assignemnt3')\n",
    "    CODE_PATH = BASE_PATH / 'code'\n",
    "\n",
    "# Define data root path (contains tiny_dataset and main_dataset)\n",
    "DATA_ROOT = BASE_PATH / 'data'\n",
    "\n",
    "# Verify paths exist\n",
    "if not BASE_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Base path does not exist: {BASE_PATH}\")\n",
    "if not DATA_ROOT.exists():\n",
    "    raise FileNotFoundError(f\"Data root does not exist: {DATA_ROOT}\")\n",
    "\n",
    "print(f\"Base Path: {BASE_PATH}\")\n",
    "print(f\"Code Path: {CODE_PATH}\")\n",
    "print(f\"Data Root: {DATA_ROOT}\")\n",
    "print(f\"\\nPath verification: OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6789cf0",
   "metadata": {},
   "source": [
    "## 3. Install Dependencies (Colab Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a497653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if running in Colab\n",
    "if IS_COLAB:\n",
    "    print(\"Installing required packages...\")\n",
    "    !pip install -q networkx==3.2.1 matplotlib==3.8.2 pandas==2.1.4 numpy==1.26.2 optuna==3.5.0\n",
    "    print(\"Packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680764d8",
   "metadata": {},
   "source": [
    "## 4. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e98d30c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahdy/projects/meta_graph_coloring_antcol/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from datetime import datetime\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Import project modules\n",
    "from dataloader import GraphDataLoader\n",
    "from optuna_tuner import OptunaACOTuner\n",
    "from aco_gpc import ACOGraphColoring\n",
    "from objective_function import aco_objective_function\n",
    "from results_utils import visualize_testing_results, export_results, print_summary_statistics, print_file_locations\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540879de",
   "metadata": {},
   "source": [
    "## 5. Configuration\n",
    "\n",
    "Define dataset selection, study name, and hyperparameter search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35e57d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Dataset: tiny_dataset\n",
      "  Study Name: aco_study_tiny_dataset_20251129_170506\n",
      "  Optuna Trials: 5\n",
      "\n",
      "Hyperparameters to Optimize:\n",
      "  iterations: [50, 200] (int)\n",
      "  num_colors: [20, 50] (int)\n",
      "  alpha: [0.5, 3.0] (float)\n",
      "  beta: [1.0, 5.0] (float)\n",
      "  rho: [0.01, 0.5] (float)\n",
      "  ant_count: [10, 50] (int)\n",
      "  Q: [0.1, 10.0] (float)\n"
     ]
    }
   ],
   "source": [
    "# Dataset selection: 'tiny_dataset' for quick testing, 'main_dataset' for full experiments\n",
    "DATASET_NAME = 'tiny_dataset'  # Change to 'main_dataset' for full tuning\n",
    "\n",
    "# Study name (will be used for study files and result organization)\n",
    "STUDY_NAME = f'aco_study_{DATASET_NAME}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "\n",
    "# Number of Optuna trials for hyperparameter tuning\n",
    "N_TRIALS = 5\n",
    "\n",
    "# ACO verbose setting \n",
    "ACO_VERBOSE = False   # Set to True to see detailed ACO progress\n",
    "\n",
    "# Hyperparameter search space configuration (parameters to optimize)\n",
    "PARAM_CONFIG = {\n",
    "    'iterations': {\n",
    "        'type': 'int',\n",
    "        'low': 50,\n",
    "        'high': 200,\n",
    "    },\n",
    "    'num_colors': {\n",
    "        'type': 'int',\n",
    "        'low': 20,\n",
    "        'high': 50,\n",
    "    },\n",
    "    'alpha': {\n",
    "        'type': 'float',\n",
    "        'low': 0.5,\n",
    "        'high': 3.0,\n",
    "    },\n",
    "    'beta': {\n",
    "        'type': 'float',\n",
    "        'low': 1.0,\n",
    "        'high': 5.0,\n",
    "    },\n",
    "    'rho': {\n",
    "        'type': 'float',\n",
    "        'low': 0.01,\n",
    "        'high': 0.5,\n",
    "    },\n",
    "    'ant_count': {\n",
    "        'type': 'int',\n",
    "        'low': 10,\n",
    "        'high': 50,\n",
    "    },\n",
    "    'Q': {\n",
    "        'type': 'float',\n",
    "        'low': 0.1,\n",
    "        'high': 10.0,\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Dataset: {DATASET_NAME}\")\n",
    "print(f\"  Study Name: {STUDY_NAME}\")\n",
    "print(f\"  Optuna Trials: {N_TRIALS}\")\n",
    "print(f\"\\nHyperparameters to Optimize:\")\n",
    "for param_name, param_spec in PARAM_CONFIG.items():\n",
    "    print(f\"  {param_name}: [{param_spec['low']}, {param_spec['high']}] ({param_spec['type']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bad981",
   "metadata": {},
   "source": [
    "## 6. Run Hyperparameter Optimization\n",
    "\n",
    "Run Optuna optimization using the objective function from separate script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64d95810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuner initialized with study: aco_study_tiny_dataset_20251129_170506\n",
      "Data root: /Users/mahdy/projects/meta_graph_coloring_antcol/assignemnt3/data\n",
      "\n",
      "Loading tuning dataset...\n",
      "\n",
      "======================================================================\n",
      "Loading Tuning Dataset: tiny_dataset\n",
      "======================================================================\n",
      "  gc_20_9:\n",
      "    Nodes: 22, Edges: 165\n",
      "    Density: 0.7143, Connected: False\n",
      "  gc_4_1:\n",
      "    Nodes: 5, Edges: 4\n",
      "    Density: 0.4000, Connected: True\n",
      "  gc_50_9:\n",
      "    Nodes: 52, Edges: 1104\n",
      "    Density: 0.8326, Connected: False\n",
      "======================================================================\n",
      "\n",
      "Loaded 3 graphs for tuning\n",
      "\n",
      "Objective function wrapper ready!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahdy/projects/meta_graph_coloring_antcol/assignemnt3/code/optuna_tuner.py:59: FutureWarning: JournalFileStorage has been deprecated in v4.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v4.0.0. Use :class:`~optuna.storages.journal.JournalFileBackend` instead.\n",
      "  self.storage = JournalStorage(JournalFileStorage(str(self.journal_file)))\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Optuna tuner\n",
    "tuner = OptunaACOTuner(\n",
    "    study_name=STUDY_NAME,\n",
    "    data_root=str(DATA_ROOT),\n",
    "    direction='minimize'  # We want to minimize the number of colors used\n",
    ")\n",
    "\n",
    "print(f\"Tuner initialized with study: {STUDY_NAME}\")\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "\n",
    "# Load tuning dataset once (before optimization)\n",
    "print(\"\\nLoading tuning dataset...\")\n",
    "data_loader = GraphDataLoader(str(DATA_ROOT), DATASET_NAME)\n",
    "tuning_graphs = data_loader.load_tuning_dataset()\n",
    "print(f\"Loaded {len(tuning_graphs)} graphs for tuning\\n\")\n",
    "\n",
    "# Wrapper function to pass tuning graphs to objective function\n",
    "def objective_wrapper(trial, params, **kwargs):\n",
    "    return aco_objective_function(\n",
    "        trial=trial,\n",
    "        params=params,\n",
    "        tuning_graphs=tuning_graphs,\n",
    "        aco_class=ACOGraphColoring,\n",
    "        verbose=ACO_VERBOSE\n",
    "    )\n",
    "\n",
    "print(\"Objective function wrapper ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d076f0",
   "metadata": {},
   "source": [
    "## 7. Run Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a4bbc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-29 17:05:06,926] A new study created in Journal with name: aco_study_tiny_dataset_20251129_170506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting hyperparameter optimization with 5 trials...\n",
      "======================================================================\n",
      "Created new study 'aco_study_tiny_dataset_20251129_170506'\n",
      "Completed trials: 0/5\n",
      "Remaining trials: 5\n",
      "\n",
      "Starting optimization with 5 trials...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-29 17:05:06,941] Trial 0 failed with parameters: {'iterations': 125, 'num_colors': 28, 'alpha': 1.93146941708432, 'beta': 1.9396633117117479, 'rho': 0.14429455679687583, 'ant_count': 23, 'Q': 6.315065977804529} because of the following error: AttributeError(\"'OptunaACOTuner' object has no attribute 'data_loader'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mahdy/projects/meta_graph_coloring_antcol/venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/Users/mahdy/projects/meta_graph_coloring_antcol/assignemnt3/code/optuna_tuner.py\", line 214, in wrapped_objective\n",
      "    data_loader=self.data_loader,\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'OptunaACOTuner' object has no attribute 'data_loader'\n",
      "[W 2025-11-29 17:05:06,943] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OptunaACOTuner' object has no attribute 'data_loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStarting hyperparameter optimization with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN_TRIALS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m trials...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m best_params = \u001b[43mtuner\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjective_func\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobjective_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparam_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPARAM_CONFIG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43maco_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mACOGraphColoring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_TRIALS\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOptimization completed!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/meta_graph_coloring_antcol/assignemnt3/code/optuna_tuner.py:223\u001b[39m, in \u001b[36mOptunaACOTuner.optimize\u001b[39m\u001b[34m(self, objective_func, param_config, aco_class, n_trials, aco_fixed_params, timeout, n_jobs, show_progress_bar)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;66;03m# Run optimization\u001b[39;00m\n\u001b[32m    222\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStarting optimization with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mremaining\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m trials...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwrapped_objective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[38;5;66;03m# Store best results\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[38;5;28mself\u001b[39m.best_params = \u001b[38;5;28mself\u001b[39m.study.best_params\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/meta_graph_coloring_antcol/venv/lib/python3.12/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/meta_graph_coloring_antcol/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:67\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/meta_graph_coloring_antcol/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:164\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/meta_graph_coloring_antcol/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:262\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    258\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    261\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/meta_graph_coloring_antcol/venv/lib/python3.12/site-packages/optuna/study/_optimize.py:205\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    208\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/meta_graph_coloring_antcol/assignemnt3/code/optuna_tuner.py:214\u001b[39m, in \u001b[36mOptunaACOTuner.optimize.<locals>.wrapped_objective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m    205\u001b[39m         suggested_params[param_name] = trial.suggest_categorical(\n\u001b[32m    206\u001b[39m             param_name,\n\u001b[32m    207\u001b[39m             param_spec[\u001b[33m'\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    208\u001b[39m         )\n\u001b[32m    210\u001b[39m \u001b[38;5;66;03m# Call user's objective function with data_loader\u001b[39;00m\n\u001b[32m    211\u001b[39m score = objective_func(\n\u001b[32m    212\u001b[39m     trial=trial,\n\u001b[32m    213\u001b[39m     params=suggested_params,\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     data_loader=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_loader\u001b[49m,\n\u001b[32m    215\u001b[39m     aco_class=aco_class,\n\u001b[32m    216\u001b[39m     fixed_params=aco_fixed_params \u001b[38;5;28;01mif\u001b[39;00m aco_fixed_params \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    217\u001b[39m )\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "\u001b[31mAttributeError\u001b[39m: 'OptunaACOTuner' object has no attribute 'data_loader'"
     ]
    }
   ],
   "source": [
    "# Run the hyperparameter optimization\n",
    "print(f\"\\nStarting hyperparameter optimization with {N_TRIALS} trials...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "best_params = tuner.optimize(\n",
    "    objective_func=objective_wrapper,\n",
    "    param_config=PARAM_CONFIG,\n",
    "    aco_class=ACOGraphColoring,\n",
    "    n_trials=N_TRIALS\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Optimization completed!\")\n",
    "print(\"\\nBest Parameters Found:\")\n",
    "for param_name, param_value in best_params.items():\n",
    "    print(f\"  {param_name}: {param_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca430a7",
   "metadata": {},
   "source": [
    "## 8. Generate Optimization Visualizations\n",
    "\n",
    "Generate and display plots showing the optimization history, parameter importances, and parallel coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8c6ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all optimization plots\n",
    "print(\"Generating optimization plots...\")\n",
    "tuner.generate_plots(recreate=True)\n",
    "print(f\"Plots saved to: {DATA_ROOT / 'figures'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63621ea5",
   "metadata": {},
   "source": [
    "## 9. Test Best Parameters on Testing Dataset\n",
    "\n",
    "Evaluate the best parameters on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de009c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader for testing\n",
    "test_loader = GraphDataLoader(str(DATA_ROOT), DATASET_NAME)\n",
    "\n",
    "# Store testing results\n",
    "testing_results = {}\n",
    "\n",
    "print(\"\\nEvaluating best parameters on testing dataset...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "# Test on each graph in the testing dataset\n",
    "for graph_name, graph in test_loader.load_testing_dataset():\n",
    "    print(f\"\\nTesting on graph: {graph_name}\")\n",
    "    \n",
    "    # Create ACO instance with best parameters and double iterations for thorough testing\n",
    "    test_params = best_params.copy()\n",
    "    test_params['iterations'] = int(test_params['iterations'] * 2)\n",
    "    test_params['verbose'] = True\n",
    "    \n",
    "    aco = ACOGraphColoring(graph=graph, **test_params)\n",
    "    \n",
    "    # Run ACO optimization\n",
    "    result = aco.run()\n",
    "    \n",
    "    # Store results\n",
    "    testing_results[graph_name] = {\n",
    "        'color_count': result['color_count'],\n",
    "        'conflict_count': result['conflict_count'],\n",
    "        'iterations_used': result['iterations'],\n",
    "        'best_solution': result['best_solution']\n",
    "    }\n",
    "    \n",
    "    print(f\"  Final Colors: {result['color_count']}\")\n",
    "    print(f\"  Final Conflicts: {result['conflict_count']}\")\n",
    "\n",
    "print(\"Testing completed!\")\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f980d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results and generate visualizations\n",
    "exported_files = export_results(testing_results, best_params, STUDY_NAME, DATA_ROOT)\n",
    "figure_path = visualize_testing_results(testing_results, STUDY_NAME, DATA_ROOT)\n",
    "\n",
    "print(f\"\\nResults exported successfully!\")\n",
    "print(f\"Testing figure saved to: {figure_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c119315",
   "metadata": {},
   "source": [
    "## 10. Display Results\n",
    "\n",
    "Show the testing results figure and summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed0e960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the testing results figure\n",
    "display(Image(filename=str(figure_path)))\n",
    "\n",
    "# Print summary statistics\n",
    "print_summary_statistics(exported_files['summary_df'])\n",
    "\n",
    "# Print file locations\n",
    "print_file_locations(STUDY_NAME, DATA_ROOT, exported_files, figure_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
