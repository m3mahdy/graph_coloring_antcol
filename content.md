POPULATION BASED METAHEURISTICS (P-METAHEURISTICS)Common Concepts for P-metaheuristicsP-metaheuristics can be viewed as an iterative improvement in a population of solutions.The process involves:Initialization: The population is initialized.Generation: A new population of solutions is generated.Replacement: The new population is integrated into the current one using some selection procedure.Stopping Criteria: The search process stops when a given condition is satisfied.Examples of P-metaheuristics include: Evolutionary Algorithms (EA), Scatter Search (SS), Particle Swarm Optimization (PSO), Ant Colony Optimization (ACO), Bee Colony (BC), and Artificial Immune Systems (AIS).High-Level Template of P-metaheuristics:P = P(0) /* Generation of the initial population */
t = 0;
Repeat
    Generate (P'(t)); /* Generation a new population */
    P(t+1) = Select-Population( P(t) $\cup$ P'(t) ); /* Select new population */
    t = t + 1;
Until Stopping criteria satisfied
Output: Best solution(s) found.
Search MemoryRepresents the set of information extracted and memorized during the search.In some cases (e.g., EA), the search memory is limited to the population of solutions (memory-less).In ACO, the pheromone matrix is the main concept of the search memory.1.1 GenerationP-metaheuristics may be classified into two main categories:Evolution based: Solutions are selected and reproduced using variation operators (e.g., mutation and recombination) acting directly on their representations. The recombination operator may involve two or more solutions. 2.  Blackboard based: Solutions of the population participate in the construction of a shared memory, which will be used as the main input for generating the new population. Recombination is indirect through the shared memory (e.g., ACO, where solutions generated by past ants affect future solutions via the pheromone matrix).1.2 ReplacementSelecting the new population from the union of the old population and the generated population.Traditional Strategy: The newly generated population completely replaces the old one.Elitism: The best solutions from both sets (parents and offspring) are selected.In blackboard-based P-metaheuristics, there is no explicit selection; the old population updates the shared search memory.1.3 Initial Population (Diversification)The main issue in the generation of the initial population is diversification. If the initial population is not well diversified, premature convergence may happen (e.g., when a greedy heuristic is used).Strategies for generating the new population:Random generation: The initial population is generated randomly.Sequential Diversification: Solutions are generated in sequence such that diversity is optimized (e.g., new solution must be at a minimum distance to all existing solutions). The drawback is high computation cost.Parallel Diversification: Solutions of a population are generated in parallel (e.g., ensuring for each object $i$ and location $j$, there is a solution where object $i$ is mapped to location $j$).Heuristic Initialization: Using any heuristic (e.g., greedy), often randomized to obtain different solutions (Greedy Randomized). Drawback is potential loss of diversity leading to premature convergence.1.4 Stopping CriteriaStatic Procedure: The end of the search is known a priori (e.g., fixed number of iterations/generations, limit on CPU resources).Adaptive Procedure: The end of the search is not known a priori (e.g., fixed number of generations without improvement, reaching an optimum, or diversity measure falling below a given threshold).Evolutionary Algorithms (EA)EAs are stochastic P-metaheuristics based on the notion of competition and evolution of species.A Generation in EAs:Population: Initially generated at random.Fitness: An objective function associates a fitness value with each solution.Selection: Individuals are selected to form the parents, with a bias toward higher fitness.Reproduction: Selected individuals are reproduced using variation operators (crossover, mutation) to generate new offspring.Replacement: A scheme is applied to determine which individuals survive from the offspring and the parents.Template of an Evolutionary Algorithm:Generate P(0)); /* Initial population */
t = 0;
While not Termination_Criterion (P(t)) Do
    Evaluate P(t));
    P'(t) = Selection(P(t));
    P'(t) = Reproduction( P'(t) );
    Evaluate P'(t));
    P(t+1) = Replace( P(t), P'(t) );
    t = t + 1;
End While
Output Best individual or best population found.
Genotype vs. PhenotypeGenotype (chromosome): The encoding of the solution. Variation operators (mutation, crossover) act on this level.Phenotype (solution): The actual solution. The fitness function uses the phenotype for evaluation.Decoding Function: Used to transform the genotype into a phenotype.Main Schools of EAAlgorithmOriginRepresentationMain OperatorFocusGAJ. Holland (USA) (1970s)Binary strings (later real-coded)Crossover + mutationGeneral optimizationESRechenberg & Schwefel (Germany) (1960s)Real-valued vectorsMutation + self-adaptationEngineering, continuous optimizationEPL. Fogel (USA) (1960s)Finite State machinesMutation onlyBehavioral modeling, predictionGPJ. Koza (USA) (1990s)Tree-structured programsCrossover + mutationProgram evolution, symbolic regressionCommon Concepts of EAs1. RepresentationChromosome: The encoded solution (individual).Gene: The decision variables within the solution (chromosome).Allele: The possible values of the variables (genes).Locus: The position of an element (gene) within a chromosome.2. Population InitializationA common search component for all P-metaheuristics.3. Objective Function / FitnessIn the EA community, the term fitness refers to the objective function.4. Selection Strategy"Which parents are chosen for reproduction, with a bias toward better fitness?" The main principle is: "the better an individual, the higher its chance of being parent."Fitness Assignment:Proportional Fitness Assignment: Absolute fitness values are associated with individuals.Rank-based Fitness Assignment: Relative fitness values are assigned (e.g., a rank in the population).Selection Methods:Roulette Wheel Selection:The most common selection strategy.Assigns each individual a selection probability proportional to its relative fitness: $$p_{i} = f_{i} / (\sum_{j=1}^{n}f_{j})$$Individuals are assigned a space on a pie graph proportional to fitness. Selection is performed by independent spins of the wheel.Drawback: Outstanding individuals may introduce a bias, causing premature convergence (loss of diversity).Stochastic Universal Sampling (SUS):Reduces the bias of roulette wheel selection.An outer roulette wheel is placed around the pie with equally spaced pointers.A single spin simultaneously selects all $\mu$ individuals for reproduction, allowing for diversity.Tournament Selection:Randomly select $k$ individuals (tournament size $k$).A tournament is applied to the $k$ members, and the best one is selected.The procedure is repeated $\mu$ times to select $\mu$ individuals.Rank-Based Selection:Uses the individual's rank $r(i)$ instead of its raw fitness value.The rank may be scaled linearly using the formula: $$p(i) = \frac{2-s}{\mu} + \frac{2 \cdot r(i) (s-1)}{\mu (\mu-1)}$$Where $s$ is the selection pressure ($1.0 < s \le 2.0$), $\mu$ is the population size, and $r(i)$ is the rank.A large $s$ gives more importance to better individuals.5. Reproduction Strategy (Variation)Applies variation operators: Mutation (unary) and Crossover (binary/n-ary).Mutation (Unary Operator)Represents small changes of the selected individual.The probability $p_{m}$ represents the probability to mutate each element (gene) of the chromosome. Small values are generally recommended, e.g., $p_{m} \in [0.001, 0.01]$.Ergodicity: Mutation should allow every solution to be reached.Validity: Mutation should produce valid solutions (not always possible for constrained problems).Locality: Mutation should produce minimal change in the genotype, resulting in small changes in the phenotype. Weak locality means small genotype changes lead to large phenotype changes (highly disruptive mutation).Mutation Types:Binary representation: Flip operator.Discrete representation: Changing the value of an element by another value of the alphabet.Permutations: Swapping, inversion, or insertion operators (e.g., 2-opt).Real valued vectors: $x' = x + m$, where $m$ is a random variable in the interval $[-a, a]$.Genetic Programming (Parse Trees): Grow (terminal node replaced by subtree), Shrink (internal subtree replaced by terminal node), Switch (two subtrees are switched), Cycle (a node is replaced by another with the same number of arguments).Recombination or Crossover (Binary/n-ary Operator)Inherits characteristics from two (or more) parents to generate offspring.Crossover Rate ($P_{c}$): The proportion of parents on which a crossover operator will act. Common rates are $P_{c} \in [0.45, 0.95]$.Heritability: Crossover should inherit genetic material from both parents.Respectful: Common decisions in both parents are preserved.Assorting: The distance between the parent and offspring is lower or equal to the distance between the parents: $d(p_{1},o) \le d(p_{1},p_{2})$ and $d(p_{2},o) \le d(p_{1},p_{2})$.Validity: The crossover operator should produce valid solutions.Crossover Types:1-point, 2-point, n-point crossover: $n$ crossover sites are selected, and offspring are generated by interchanging segments. * Uniform crossover: Each element of the offspring is selected randomly from either parent.Crossovers for Permutations (Feasible Solutions):Order Crossover:Two crossover points are randomly selected from Parent 1.The segment between the two points is copied from Parent 1 to the offspring.Elements from Parent 2 that are not already in the offspring are picked in order, starting from the second crossover point, and placed in the remaining empty slots of the offspring. 2.  Two-point Crossover (for permutations): Elements outside the selected two points are inherited from one parent, and the other elements are placed in the order of appearance in the other parent. 3.  Partially Matched Crossover (PMX): Two crossing sites define a matching section used to perform position-by-position exchange operations.6. Replacement StrategySurvivor selection from both the parent and the offspring populations to maintain a fixed population size.Generational Replacement: Offspring completely replace the parent population.Steady-state replacement: Only one offspring is generated at each generation, typically replacing the worst individual of the parent population.Elitism: Selecting the best individuals from both the parents and the offspring to survive.7. Parameters of EAsMutation Probability ($P_{m}$): Generally small values, e.g., $[0.001, 0.01]$. Large $P_{m}$ disrupts individuals and makes the search random.Crossover Probability ($P_{c}$): Generally medium to large values, e.g., $[0.45, 0.95]$.Population Size: Larger size leads to better convergence, but time complexity grows linearly. Practice suggests a size usually between $20$ and $100$. Parameters need to be tuned for the best set.Scatter Search (SS)SS is a deterministic strategy applied to combinatorial and continuous optimization problems.SS Procedure:Initialization: Generate an initial population (POP) satisfying criteria of diversity and quality.Reference Set Construction: Construct a reference set ($RefSet$) of moderate size (e.g., $10$ solutions) from the good solutions in POP.Combination: Selected solutions are combined (similar to crossover) to provide starting solutions for an improvement procedure.Improvement: An improvement procedure (based on S-metaheuristics) is applied.Reference Set Update: $RefSet$ is updated based on the results to incorporate both high quality and diversified solutions.Repetition: The process is repeated until a stopping criterion is satisfied.SS Components:Diversification Generation Method: Generates a set of diverse initial solutions (e.g., using a greedy procedure).Improvement Method: Transforms a trial solution into enhanced solutions using any S-metaheuristic (e.g., local search).Reference Set Update Method: Must ensure diversity while keeping high-quality solutions.Subset Generation Method: Operates on $RefSet$ to generate a subset of solutions (e.g., all subsets of size $r=3$) as a basis for combination. It is deterministic, unlike EA selection.Solution Combination Method: A generalization of the crossover operator where more than two individuals are recombined.